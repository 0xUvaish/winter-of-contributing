{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Adaptive_Resonance_Theory.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBMi2jnlx-Jv"
      },
      "source": [
        "# Adaptive Resonance Theory Neural Networks\n",
        "Adaptive resonance theory is a type of neural network technique developed by Stephen Grossberg and Gail Carpenter in 1987. It is based on competition and uses unsupervised learning model. Adaptive Resonance Theory ART networks, as the name suggests, is always open to new learning adaptive without losing the old patterns resonance. Basically, ART network is a vector classifier which accepts an input vector and classifies it into one of the categories depending upon which of the stored pattern it resembles the most.\n",
        "\n",
        "### ART1 demo\n",
        "In this example:\n",
        " * We'll use 10x10 ASCII blocks to demonstrate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "0INaH8x0x-J0"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcLdnTsyx-J1"
      },
      "source": [
        "data = np.array([\"   O \",\n",
        "        \"  O O\",\n",
        "        \"    O\",\n",
        "        \"  O O\",\n",
        "        \"    O\",\n",
        "        \"  O O\",\n",
        "        \"    O\",\n",
        "        \" OO O\",\n",
        "        \" OO  \",\n",
        "        \" OO O\",\n",
        "        \" OO  \",\n",
        "        \"OOO  \",\n",
        "        \"OO   \",\n",
        "        \"O    \",\n",
        "        \"OO   \",\n",
        "        \"OOO  \",\n",
        "        \"OOOO \",\n",
        "        \"OOOOO\",\n",
        "        \"O    \",\n",
        "        \" O   \",\n",
        "        \"  O  \",\n",
        "        \"   O \",\n",
        "        \"    O\",\n",
        "        \"  O O\",\n",
        "        \" OO O\",\n",
        "        \" OO  \",\n",
        "        \"OOO  \",\n",
        "        \"OO   \",\n",
        "        \"OOOO \",\n",
        "        \"OOOOO\"])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "KveCut7ux-J2"
      },
      "source": [
        "## Simplied ART1\n",
        "\n",
        "class ART1:\n",
        "    \"\"\"\n",
        "    ART class\n",
        "    modified Aman Ahuja\n",
        "    \n",
        "    Usage example:\n",
        "    --------------\n",
        "    # Create a ART network with input of size 5 and 20 internal units\n",
        "    >>> network = ART(5,10,0.5)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n=5, m=10, rho=.5):\n",
        "        '''\n",
        "        Create network with specified shape\n",
        "        \n",
        "        For Input array I of size n, we need n input nodes in F1. \n",
        "        \n",
        "        \n",
        "        Parameters:\n",
        "        -----------\n",
        "        n : int\n",
        "            feature dimension of input; number of nodes in F1\n",
        "        m : int\n",
        "            Number of neurons in F2 competition layer\n",
        "            max number of categories\n",
        "            compare to n_class\n",
        "        rho : float\n",
        "            Vigilance parameter\n",
        "            larger rho: less inclusive prototypes\n",
        "            smaller rho: more generalization\n",
        "        \n",
        "        internal paramters\n",
        "        ---------- \n",
        "        F1: array of size (n)\n",
        "            array of F1 neurons\n",
        "        F2: array of size (m)\n",
        "            array of F2 neurons\n",
        "        Wf: array of shape (m x n)\n",
        "            Feed-Forward weights\n",
        "            These are Tk\n",
        "        Wb: array of shape (n x m)\n",
        "            Feed-back weights\n",
        "        n_cats : int\n",
        "            Number of F2 neurons that are active\n",
        "            (at any given time, number of category templates)\n",
        "        \n",
        "        '''\n",
        "        # Comparison layer\n",
        "        self.F1 = np.ones(n)\n",
        "        \n",
        "        # Recognition layer\n",
        "        self.F2 = np.ones(m)\n",
        "        \n",
        "        # Feed-forward weights\n",
        "        self.Wf = np.random.random((m,n))\n",
        "        \n",
        "        # Feed-back weights\n",
        "        self.Wb = np.random.random((n,m))\n",
        "        \n",
        "        # Vigilance parameter\n",
        "        self.rho = rho\n",
        "        \n",
        "        # Number of active units in F2\n",
        "        self.n_cats = 0\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"Reset whole network to start conditions\n",
        "        \"\"\"\n",
        "        self.F1 = np.ones(n)\n",
        "        self.F2 = np.ones(m)\n",
        "        self.Wf = np.random.random((m,n))\n",
        "        self.Wb = np.random.random((n,m))\n",
        "        self.n_cats = 0 \n",
        "        \n",
        "    def learn(self, X):\n",
        "        \"\"\"Learn X\n",
        "        use i as index over inputs or F1\n",
        "        use k as index over categories or F2\n",
        "        \"\"\" \n",
        "\n",
        "        # Compute F2 output using feed forward weights\n",
        "        self.F2[...] = np.dot(self.Wf, X)\n",
        "        \n",
        "        # collect and sort the output of each active node (C)\n",
        "        C = np.argsort(self.F2[:self.n_cats].ravel())[::-1]\n",
        "\n",
        "        for k in C:\n",
        "            # compute nearest memory\n",
        "            d = (self.Wb[:,k]*X).sum()/X.sum()\n",
        "\n",
        "            # Check if d is above the vigilance level\n",
        "            if d >= self.rho:\n",
        "                ww = self._learn_data(k, X)\n",
        "                return ww\n",
        "            else: \n",
        "                pass\n",
        "\n",
        "        # No match found within vigilance level\n",
        "        # If there's room, increase the number of active units\n",
        "        # and make the newly active unit to learn data\n",
        "        if self.n_cats < self.F2.size:\n",
        "            k = self.n_cats  # index of last category\n",
        "            ww = self._learn_data(k, X)\n",
        "            self.n_cats += 1\n",
        "            return ww\n",
        "        else: \n",
        "            return None,None\n",
        "\n",
        "    def _learn_data(self, node, dat):\n",
        "        \"\"\"\n",
        "        node : i : F2 node\n",
        "        dat  : X : input data\n",
        "        \"\"\" \n",
        "        self._validate_data(dat)\n",
        "        \n",
        "        # Learn data\n",
        "        self.Wb[:,node] *= dat\n",
        "        self.Wf[node,:] = self.Wb[:,node]/(0.5+self.Wb[:,node].sum())\n",
        "        return self.Wb[:,node], node\n",
        "    \n",
        "    def predict(self, X):\n",
        "        C = np.dot(self.Wf[:self.n_cats], X)\n",
        "\n",
        "        #return active F2 node, unless none are active\n",
        "        if np.all(C == 0):\n",
        "            return None\n",
        "\n",
        "        return np.argmax(C)\n",
        "\n",
        "    def _validate_data(self, dat):\n",
        "        \"\"\"\n",
        "        dat is a single input record\n",
        "        Checks: data must be 1s and 0s\n",
        "        \"\"\"\n",
        "        pass_checks = True\n",
        "        \n",
        "        # Dimensions must match\n",
        "        if dat.shape[0] != len(self.F1):\n",
        "            pass_checks = False\n",
        "            msg = \"Input dimensins mismatch.\"\n",
        "        \n",
        "        # Data must be 1s or 0s\n",
        "        if not np.all((dat == 1) | (dat == 0)):\n",
        "            pass_checks = False\n",
        "            msg = \"Input must be binary.\"\n",
        "        \n",
        "        if pass_checks:\n",
        "            return True\n",
        "        else: \n",
        "            raise Exception(\"Data does not validate: {}\".format(msg))\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQMIcqHMx-J4"
      },
      "source": [
        "### Cleaning and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "9msiHtrlx-J4"
      },
      "source": [
        "\"\"\"\n",
        "Helper function\n",
        "\"\"\"\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "def preprocess_data(data): \n",
        "    \"\"\"\n",
        "    Convert to numpy array\n",
        "    Convert to 1s and 0s\n",
        "    \n",
        "    \"\"\"\n",
        "    # Look at first row\n",
        "    if data[0]: \n",
        "        irow = data[0]\n",
        "\n",
        "        # get size\n",
        "        idat_size = len(irow)\n",
        "\n",
        "        # get unique characters\n",
        "        chars = False\n",
        "        while not chars: \n",
        "            chars = get_unique_chars(irow, reverse=True)\n",
        "        char1, char2 = chars\n",
        "\n",
        "    outdata = []\n",
        "    idat = np.zeros(idat_size, dtype=bool)\n",
        "\n",
        "    for irow in data:\n",
        "        idat = [x==char1 for x in irow]\n",
        "        outdata.append(idat)\n",
        "    \n",
        "    return np.array(outdata).astype(int)\n",
        "\n",
        "def get_unique_chars(irow, reverse=False):\n",
        "    \"\"\"\n",
        "    Get unique characters in data\n",
        "    Helper function\n",
        "    ---- \n",
        "    reverse:   bool\n",
        "        Reverses order of the two chars returned\n",
        "    \"\"\"\n",
        "    chars = Counter(irow)\n",
        "    if len(chars) > 2: \n",
        "        raise Exception(\"Data is not binary\")\n",
        "    elif len(chars) < 2: \n",
        "        # first row doesn't contain both chars\n",
        "        return False, False\n",
        "\n",
        "    # Reorder here?\n",
        "    if reverse: \n",
        "        char2, char1 = chars.keys()\n",
        "    else: \n",
        "        char1, char2 = chars.keys()\n",
        "    \n",
        "    return char1, char2\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVbcJRPDx-J5"
      },
      "source": [
        "### DO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IefQhXyyx-J5",
        "outputId": "eff3e677-b8a1-4afe-8c0d-14c496459363"
      },
      "source": [
        "network = ART1(n=5, m=7, rho=0.5)\n",
        "\n",
        "# preprocess data\n",
        "data_cleaned = preprocess_data(data)\n",
        "\n",
        "# learn data array, row by row\n",
        "for row in data_cleaned:\n",
        "    network.learn(row)\n",
        "\n",
        "print (\"n categories: \", network.n_cats)\n",
        "#print tt"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n categories:  7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lBh5gPEx-J6"
      },
      "source": [
        "### Predictions\n",
        "\n",
        "Let's see the clusters created through training: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFdRUhCLx-J6",
        "outputId": "b60cc090-1c11-488c-c34a-e9c6087fcc63"
      },
      "source": [
        "network.n_cats"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MuRuLxax-J7",
        "outputId": "37b8819e-0c3b-4c11-ec9f-728b254ad646"
      },
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "output_dict = defaultdict(list)\n",
        "\n",
        "for row, row_cleaned in zip (data, data_cleaned): \n",
        "    pred = network.predict(row_cleaned)\n",
        "    output_dict[pred].append(row)\n",
        "\n",
        "for k,v in output_dict.items():\n",
        "    print (k)\n",
        "    print ('-----')\n",
        "    for row in v: \n",
        "        print (row)\n",
        "    print \n",
        "#   \\  print \"'{}':{}\".format(\n",
        "#         row, \n",
        "#         network.predict(row_cleaned))\n",
        "    "
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "-----\n",
            "   O \n",
            "   O \n",
            "1\n",
            "-----\n",
            "  O O\n",
            "  O O\n",
            "  O O\n",
            "  O  \n",
            "  O O\n",
            "2\n",
            "-----\n",
            "    O\n",
            "    O\n",
            "    O\n",
            "    O\n",
            "5\n",
            "-----\n",
            " OO O\n",
            " OO  \n",
            " OO O\n",
            " OO  \n",
            "OOO  \n",
            "OOO  \n",
            "OOOO \n",
            "OOOOO\n",
            " OO O\n",
            " OO  \n",
            "OOO  \n",
            "OOOO \n",
            "OOOOO\n",
            "6\n",
            "-----\n",
            "OO   \n",
            "OO   \n",
            " O   \n",
            "OO   \n",
            "None\n",
            "-----\n",
            "O    \n",
            "O    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voLHphvRx-J7"
      },
      "source": [
        "### Look at the weights as patterns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rd7uGEQ1x-J7",
        "outputId": "abf47911-c276-4319-d6a8-b55816068f27"
      },
      "source": [
        "cluster_units = network.Wf[:network.n_cats]\n",
        "for idx, CU_weights in enumerate(cluster_units):\n",
        "    pattern = CU_weights\n",
        "    pattern = pattern.astype(bool)\n",
        "    \n",
        "    print (\"Pattern #{}\".format(idx))\n",
        "    print (pattern.astype(int))\n",
        "    print\n",
        "    #preprocess_data(pattern)\n",
        "    #print np.round(pattern)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pattern #0\n",
            "[0 0 0 1 0]\n",
            "Pattern #1\n",
            "[0 0 1 0 0]\n",
            "Pattern #2\n",
            "[0 0 0 0 1]\n",
            "Pattern #3\n",
            "[0 0 0 0 1]\n",
            "Pattern #4\n",
            "[0 0 0 0 1]\n",
            "Pattern #5\n",
            "[0 1 1 0 0]\n",
            "Pattern #6\n",
            "[0 1 0 0 0]\n"
          ]
        }
      ]
    }
  ]
}