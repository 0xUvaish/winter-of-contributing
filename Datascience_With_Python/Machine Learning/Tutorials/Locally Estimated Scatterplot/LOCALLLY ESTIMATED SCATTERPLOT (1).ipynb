{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LOCALLLY ESTIMATED SCATTERPLOT.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPNE//7BgG9CyX9QKIixl8/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Wb-pUBhALWy8"},"source":["\n","# **LOCALLY ESTIMATED SCATTERPLOT**\n","\n","- LOESS, originally proposed by Cleveland (1979) and further developed by Cleveland and Devlin (1988), specifically denotes a method that is (somewhat) more descriptively known as locally weighted polynomial regression.\n","\n","- LOESS is one of many \"modern\" modeling methods that build on \"classical\" methods, such as linear and nonlinear least squares regression.Modern regression methods are designed to address situations in which the classical procedures do not perform well or cannot be effectively applied without undue labor.\n","\n","\n","- Loess stands for locally estimated scatterplot smoothing (lowess stands for\n","locally weighted scatterplot smoothing) and is one of many non-parametric\n","regression techniques, but arguably the most flexible. \n","\n","-  A smoothing function is a function that attempts to capture general patterns in stressor-response\n","relationships while reducing the noise and it makes minimal assumptions about\n","the relationships among variables.\n","\n","-  The result of a loess application is a line\n","through the moving central tendency of the stressor-response relationship.\n","\n","- Loess is essentially used to visually assess the relationship between two\n","variables and is especially useful for large datasets, where trends can be hard to\n","visualize. \n","\n","\n","> # How does it work? \n","\n","- Loess is fairly\n","straightforward. \n","\n","- A\n","specific width of points\n","along the x axis is\n","selected (the bandwidth\n","or tension) adjacent to\n","the point being predicted,\n","and a low degree\n","polynomial equation\n","(often just linear) is fit\n","through that subset of\n","the data. More weight is\n","given to points closest to\n","the value being\n","predicted. This resulting\n","equation is then used to\n","predict the value for the selected point. \n","\n","- The data are then shifted one\n","point to the right and the process continues, with a new prediction for the\n","second point, and so on. The resulting points are then connected together\n","with a line. \n","\n","- The user can control how wide a band of points are used – the\n","smaller the bandwidth, the fewer points that are used and the less smooth the\n","final line. Users can also adjust the type of line-fitting that is used – weighted\n","least squares is the most common. Users can also adjust what types of\n","weights are used.\n","\n","># Some Assumptions:\n","\n","• Very few\n","\n","• Need a lot lot of data – the more the better \n","\n","# Data Requirements\n","\n","Independently collected numeric data in the form of paired observations are best.\n","\n"," These are typically\n","continuous numeric data, although discrete numeric data can be used. \n","\n","As with correlation and regression,\n","the greater the range of environmental conditions encompassed the better.\n","\n","#  REGRESSION\n","\n","Regression is a mathematical function which show the relationship between one dependent variable and one more variable. The obtained function is called regression equation.\n","\n","# SMOOTHING\n","\n","Smoothing is a technique to group variables with similar expectations and fit a suitable curve. It helps to decrease the volatility in data series. Therefore trend can be observed clearly.\n","\n","# WEIGHT FUNCTION\n","\n","Weight Function\t gives the most weight to the data points nearest the point of estimation and the least weight to the data points that are furthest away.\n","\n","The use of the weights is based on the idea that points near each other in the explanatory variable space are more likely to be related to each other in a simple way than points that are further apart.\n","\n","\n","Following this logic, points that are likely to follow the local model best influence the local model parameter estimates the most. Points that are less likely to actually conform to the local model have less influence on the local model parameter estimates.\n","\n","The traditional weight function used for LOESS is the tri-cube weight function,\n","\n","     w(x)={(1−|x|^3)^3  for |x|<1}\n","          {0            for |x|≥1}\n","\n","            \n","However, any other weight function that satisfies the properties listed in Cleveland (1979) could also be used. \n","\n","The weight for a specific point in any localized subset of data is obtained by evaluating the weight function at the distance between that point and the point of estimation, after scaling the distance so that the maximum absolute distance over all of the points in the subset of data is exactly one.\n","\n","# EXAMPLE OF LOESS:\n","\n","Here the scatterplot will be displayed on the basis of car dataset with box plots in the margins and non-parametric regression smooth.\n","\n","\n","    x <- mtcars$wt\n","    y <- mtcars$mpg\n","\n","     plot(x, y, main = \"Main title\", \n","     xlab = \"X axis title\", ylab = \"Y axis title\",\n","        pch = 19, frame = FALSE)\n","     lines(lowess(x, y), col = \"green\")\n","\n","**Output:**\n","\n","![Picture](https://static.wixstatic.com/media/6e3b57_04b30e00419c40bc86a87f03e70c4049~mv2.jpg/v1/fill/w_477,h_272,al_c,q_90/6e3b57_04b30e00419c40bc86a87f03e70c4049~mv2.webp)\n","\n","\n","# Implementation of Locally Weighted Linear Regression(LOWESS or LOESS) in Python\n","\n",">The algorithm is used for making predictions when there exists a non-linear relationship between the features.\n","\n",">Locally weighted linear regression is a supervised learning algorithm.\n","It a non-parametric algorithm.\n","\n","Suppose we want to evaluate the hypothesis function h at a certain query point x. For linear regression we would do the following:   \n","  \n","\n","**Code: Importing Libraries**\n"," \n","\n","    import numpy as np\n","    import matplotlib.pyplot as plt\n","    import pandas as pd\n","    \n","    plt.style.use(\"seaborn\")\n","\n","**Code: Loading Data**\n"," \n","\n","\n","\n","    dfx = pd.read_csv('weightedX_LOWES.csv')\n","    dfy = pd.read_csv('weightedY_LOWES.csv')\n","    X = dfx.values\n","    Y = dfy.values\n","\n","**Output:**\n"," \n","![Picture](https://media.geeksforgeeks.org/wp-content/uploads/20200820060319/Screenshot-2020-08-20-at-10.32.57-AM.png)\n","\n","\n","\n","**Code: Function to calculate weight matrix**\n"," \n","\n","\n","\n","      def get_WeightMatrix_for_LOWES(query_point, Training_examples, Bandwidth)\n","        M = Training_examples.shape[0]\n","        W = np.mat(np.eye(M))\n","        for i in range(M):\n","          xi = Training_examples[i]\n","          denominator = (-2 * Bandwidth * Bandwidth)\n","          W[i, i] = np.exp(np.dot((xi-query_point), (xi-query_point).T)/denominator)\n","          return W\n","\n","**Code: Making Predictions:**\n"," \n","\n","\n","    def predict(training_examples, Y, query_x, Bandwidth):\n","      M = Training_examples.shape[0]\n","      all_ones = np.ones((M, 1))\n","      X_ = np.hstack((training_examples, all_ones))\n","      qx = np.mat([query_x, 1])\n","      W = get_WeightMatrix_for_LOWES(qx, X_, Bandwidth)\n","      theta = np.linalg.pinv(X_.T*(W * X_))*(X_.T*(W * Y))\n","      pred = np.dot(qx, theta)\n","      return theta, pred\n","\n","**Code: Visualise Predictions**\n"," \n","    Bandwidth = 0.1\n","    X_test = np.linspace(-2, 2, 20)\n","    Y_test = []\n","    for query in X_test:\n","      theta, pred = predict(X, Y, query, Bandwidth)\n","      Y_test.append(pred[0][0])\n","    horizontal_axis = np.array(X)\n","    vertical_axis = np.array(Y)\n","    plt.title(\"Tau / Bandwidth Param %.2f\"% Bandwidth)\n","    plt.scatter(horizontal_axis, vertical_axis)\n","    Y_test = np.array(Y_test)\n","    plt.scatter(X_test, Y_test, color ='red')\n","    plt.show()\n","\n","![Picture](https://media.geeksforgeeks.org/wp-content/uploads/20200820060106/Screenshot-2020-08-20-at-10.30.16-AM2.png)\n","\n","\n","\n","\n","\n","\n","\n","# APPLICATION \n","\n","- Fitting a line to a scatter plot where noisy data values with your ability to see a line of best fit.\n","\n","- Linear regression where least squares fitting does not create a line of good fit\n","\n","- Data explorations in social science.\n","\n","\n","\n","# ADVANTAGES\n","\n","• Simple and flexible.\n","\n","• No assumptions about the\n","relationships between variables.\n","\n","• Valuable for visualizing complex\n","relationships.\n","\n","• Users can estimate new values to\n","the fit and validate models if\n","needed.\n","\n","# DISADVANTAGES\n","\n"," • Requires densely sampled datasets.\n","\n","\n","• No ready formula is produced, so\n","it is hard to transport the results.\n","\n","\n","• Computationally intensive – but\n","not a problem for most computers.\n","\n","\n","• Sensitive to outliers.\n","\n","\n","\n","# Conclusion\n","\n","We have gone through the rationale for using the LOESS local regression model and lifted the veil on how it works. \n","\n","A Python implementation was developed and presented making heavy use of the NumPy library and its vectorization feature.\n","\n","# Purpose\n","\n","By combined with scatterplots, locally weighted scatterplot smoothing (LOESS) is used to examine biological attribute changes along a nutrient gradient. It is designed to address nonlinear relationships where linear methods do not perform well.\n","\n","\n","\n","\n"]}]}