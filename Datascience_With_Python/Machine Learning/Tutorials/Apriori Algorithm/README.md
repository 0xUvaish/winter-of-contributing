<b>Topic: Apriori Algorithm for data mining.</b>

<b>Content</b>
1. What are itemsets and frequent itemsets
2. What does apriori algorithm do?
3. Important terms
4. Steps explanation using example

<b>What are itemsets and frequent itemsets?</b><br>
When different kinds of items together form a set, it is called an itemset. If it contains k different types of items, then it is precisely called 'k-itemset'.When in a certain amount of transactions, a particular itemset is occuring frequently, it is called a frequent itemset.<br>
Now the question arises, how can we know if an itemset is occuring frequently? This is measured with the help of a quantity termed as "Minimum support threshold".
If number of occurance of an itemset is greater than or equal to this specified threshold, it is said to be occuring frequently.<br><br>

<b>What does Apriori algorithm do?</b><br>
Apriori algorithm discovers relation between different items in a dataset.It checks on which items together are forming strong association rules and hence can be called frequent itemsets. This result is useful for many real world problems including market basket analysis,health pattern identification, recommendation systems etc.<br><br>

<b>Important terms</b><br>
There are a few terms that we have to be familiar with before proceeding to understand the algorithm.They are listed here:<br>
1.Support - Suppose the support percentage of item x and y is given as 2%, it means that in 2% of the total transactions x and y were bought together. <br>
2.Confidence - Suppose the confidence percentage of items x and y is given to be 60%, then it means that about 60% customers who bought x as well as y.<br>
Both these quantities can be calculated as follows<br>![image1](https://www.softwaretestinghelp.com/wp-content/qa/uploads/2019/09/Support-and-Confidence-for-Itemset-A-and-B.png)

3.Join - The join step find all the occurances of a k-itemset in every iteration<br>
4.Prune - This step scans the count of each item in the database. If the candidate item does not meet minimum support, then it is regarded as infrequent and thus it is removed.<br>

<b>Steps involved using an example</b><br>
#1 In the first iteration of the algorithm, each item is taken as a 1-itemsets candidate. The algorithm will count the occurrences of each item.

#2 Let there be some specified minimum support, say 2. The set of 1 – itemsets whose occurrence is satisfying the min sup are determined. Only those candidates which count more than or equal to 2, are taken ahead for the next iteration and the others are pruned.

#3 Next, 2-itemset frequent items with min_sup are discovered. For this in the join step, the 2-itemset is generated by forming a group of 2 by combining items with itself.

#4 The 2-itemset candidates are pruned using min-sup threshold value. Now the table will have 2 –itemsets with min-sup only.

#5 This process goes on with increasing number of k in k-itmesets until the most frequent itemset is achieved.

Let us understand this by the following example.<br>
![image2]


