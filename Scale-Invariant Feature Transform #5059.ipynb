{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n20Av3bAWAkG"
      },
      "source": [
        "# **Scale-Invariant Feature Transform**\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5V8Ja1WWWY5h"
      },
      "source": [
        "**INTRODUCTION :**\n",
        "\n",
        "---\n",
        "\n",
        "SIFT, or Scale Invariant Feature Transform, is a feature detection algorithm in Computer Vision.\n",
        "\n",
        "SIFT helps locate the local features in an image, commonly known as the ‘keypoints‘ of the image. These keypoints are scale & rotation invariant that can be used for various computer vision applications, like image matching, object detection, scene detection, etc.\n",
        "\n",
        "We can also use the keypoints generated using SIFT as features for the image during model training. The major advantage of SIFT features, over edge features or hog features, is that they are not affected by the size or orientation of the image.\n",
        "\n",
        "It was created by David Lowe from the University British Columbia in 1999. David Lowe presents the SIFT algorithm in his original paper titled Distinctive Image Features from Scale-Invariant Keypoints.\n",
        "\n",
        "Image features extracted by SIFT are reasonably invariant to various changes such as their llumination image noise, rotation, scaling, and small changes in viewpoint.\n",
        "\n",
        "**There are four main stages involved in SIFT algorithm :**\n",
        "\n",
        "1] Scale-space extrema detection\n",
        "\n",
        "2] Keypoint localization\n",
        "\n",
        "3] Orientation Assignment\n",
        "\n",
        "4] Keypoint descriptor\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttDVY_CPZEoQ"
      },
      "source": [
        "**MAJOR ADVANTAGES OF SIFT :**  \n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**Locality:** features are local, so robust to occlusion and clutter (no prior segmentation)\n",
        "\n",
        "**Distinctiveness:** individual features can be matched to a large database of objects\n",
        "\n",
        "**Quantity:** many features can be generated for even small objects\n",
        "\n",
        "**Efficiency:** close to real-time performance\n",
        "\n",
        "**Extensibility:** can easily be extended to a wide range of different feature types, with each adding robustness"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtbMdzd0ateA"
      },
      "source": [
        "**DISADVANTAGES OF SIFT :**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "SIFT uses 128 dimensional feature vectors which are big and computational cost of SIFT due to this rises.\n",
        "\n",
        "SIFT continues to be a good detector when the images that are to be matches are nearly identical but even a relatively small change will produce a big drop in matching keypoints.\n",
        "\n",
        "SIFT cannot find too many points in the image that are resistant to scale, rotation and distortion if the original image is out of focus (blurred). Thus, it does not work well if the images are blurred."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqdWeJakcmAB"
      },
      "source": [
        "**IMPLEMENTATION** :\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eb7pyCvneCwA"
      },
      "source": [
        "# Important NOTE: Use opencv <= 3.4.2.16 as\n",
        "# SIFT is no longer available in\n",
        "# opencv > 3.4.2.16\n",
        "import cv2\n",
        "\n",
        "# Loading the image\n",
        "img = cv2.imread('geeks.jpg')\n",
        "\n",
        "# Converting image to grayscale\n",
        "gray= cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# Applying SIFT detector\n",
        "sift = cv2.xfeatures2d.SIFT_create()\n",
        "kp = sift.detect(gray, None)\n",
        "\n",
        "# Marking the keypoint on the image using circles\n",
        "img=cv2.drawKeypoints(gray ,\n",
        "\t\t\t\t\tkp ,\n",
        "\t\t\t\t\timg ,\n",
        "\t\t\t\t\tflags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
        "\n",
        "cv2.imwrite('image-with-keypoints.jpg', img)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXY-15WVZdg0"
      },
      "source": [
        "**REFERENCE LINKS :**\n",
        "\n",
        "---\n",
        "https://www.analyticsvidhya.com/blog/2019/10/detailed-guide-powerful-sift-technique-image-matching-python/\n",
        "\n",
        "https://iq.opengenus.org/scale-invariant-feature-transform/\n",
        "\n",
        "https://medium.com/data-breach/introduction-to-sift-scale-invariant-feature-transform-65d7f3a72d40\n",
        "\n",
        "https://www.geeksforgeeks.org/sift-interest-point-detector-using-python-opencv/\n"
      ]
    }
  ]
}