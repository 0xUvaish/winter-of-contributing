{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**A Breif Introduction to Generative Adversarial Network (GAN)**","metadata":{}},{"cell_type":"markdown","source":"![](https://images.app.goo.gl/Vt9xsqgFvafruVxU6)","metadata":{}},{"cell_type":"markdown","source":"Perhaps all of you heard about Deepfake where AI can generate fake speech or images which are hard to difficult to distinguish from the actual one. These systems are built on Generative Adversarial Network (GAN) and currently it's one of the most versatile neural network architecture.","metadata":{}},{"cell_type":"markdown","source":"**History of GAN**\n\n\nIn early 1960s, one of the pioneers of AI, Herbert Simon noticed that machine maybe a match of cognitive abilities of humankind , perform routine tasks. To make machine behave more human, researchers has designed an advanced neural architecture for replicating coginitive intelligence. GANs architecture has been introduced by Ian Goodfellow et. al. from University of Montreal in 2014. This model has become so popular that Yann LeCun (Facebook AI research director) addressed it as the most interesting idea in the last ten years in the world of Machine Learning.\n\n[Original GAN paper](https://arxiv.org/abs/1406.2661)","metadata":{}},{"cell_type":"markdown","source":"**How GAN actually works**\n\n\nA generative adversarial network (GAN) is a part of machine learning frameworks that trains a generative model having two sub-networks. One is a generative network, and the other is a discriminative network.\n\nGenerative Network: It works like a deconvolution network and tries to create images or speech using random noise .\nDiscriminative Network: It assesses those data and tries to differentiate between real or fake one as a convolution network.\nSo, the generative network creates candidates while the discriminative network judges them. Discriminative networks identify the general model-generated samples as real or fake. GAN training works as supervised learning. The generator produces new counterfeit data, and the discriminator learns to identify between natural and artificial data.\n\nFirstly, the generator is equipped with fixed-length random data as input. This data is drawn from predefined latent space. Then the generator is trained by deceiving the discriminator enough. Finally, the discriminator evaluates them and specifies the real and fake data. Initially, the discriminator is trained with a known dataset until it reaches acceptable accuracy. It is a simple classification model. After training has been done, the discriminator is terminated. Independent backpropagation can help to produce better sample data.\n\n![Architecture](https://images.app.goo.gl/WWDmFvCm5XQCgDRXA)","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"**Implementation**\n\nIn this code I'm implementing GAN to a  [Pokeman dataset](https://www.kaggle.com/kvpratama/pokemon-images-dataset). These images along with the fake ones will be fed in batches to the Discriminator.Let's take a look at the steps our GAN will follow-\n\nHere, two neural network will compete with each other . The discriminator will detect the ground truth ( real or fake ) of generated images and return possiblities a number between 0 and 1 . here 0 represent fake and 1 is real .-","metadata":{}},{"cell_type":"markdown","source":"**Importing Libaries**\n> This section imports all the necessary libraries to build the model as well as to plot the necessary results.","metadata":{}},{"cell_type":"code","source":"import os \nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision.datasets import ImageFolder\nimport torchvision.transforms as tt\nfrom torch.utils.data import DataLoader\nfrom torchvision.utils import make_grid,save_image\nimport cv2\nfrom tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2021-09-21T09:39:48.219731Z","iopub.execute_input":"2021-09-21T09:39:48.220062Z","iopub.status.idle":"2021-09-21T09:39:49.545704Z","shell.execute_reply.started":"2021-09-21T09:39:48.220035Z","shell.execute_reply":"2021-09-21T09:39:49.544947Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"Path = \"../input/pokemon-images-dataset/pokemon_jpg\"\n\n","metadata":{"execution":{"iopub.status.busy":"2021-09-21T09:40:23.693341Z","iopub.execute_input":"2021-09-21T09:40:23.693682Z","iopub.status.idle":"2021-09-21T09:40:23.697449Z","shell.execute_reply.started":"2021-09-21T09:40:23.693649Z","shell.execute_reply":"2021-09-21T09:40:23.696433Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"In this part,python library is called for path handling.","metadata":{}},{"cell_type":"code","source":"os.listdir(Path)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T04:43:25.775848Z","iopub.execute_input":"2021-09-21T04:43:25.77612Z","iopub.status.idle":"2021-09-21T04:43:25.797513Z","shell.execute_reply.started":"2021-09-21T04:43:25.776094Z","shell.execute_reply":"2021-09-21T04:43:25.796713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This block mainly involves the preprocessing as well as augmentation of the dataset. At first, we have resized the dataset's images  to (64,64).After that, cropping has been applied. Since we are working in pytorch, we need to convert this numpy arrays into tensor. \"tt.ToTensor\" achieves this task. And then comes the classic preprocessing task called \"Normalization\". Normalization is performed so that deep learning model can easily do the computation. Finally,horizontal flip is performed over the normalized images. To send the images easily into the network,a dataloader has been created with suitable batch size with shuffling enabled.","metadata":{}},{"cell_type":"code","source":"image_size = 64\nbatch_size = 64\nimage_channels = 3\nstats = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)\n\ntrain_ds1 = ImageFolder(Path,transform=tt.Compose([\n    tt.Resize(image_size),\n    tt.CenterCrop(image_size),\n    tt.ToTensor(),\n    tt.Normalize(*stats),\n    tt.RandomHorizontalFlip(p=0.5)\n]))\n\ntrain_dl = DataLoader(train_ds1, batch_size, shuffle=True, num_workers=3, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T04:43:25.799107Z","iopub.execute_input":"2021-09-21T04:43:25.799459Z","iopub.status.idle":"2021-09-21T04:43:26.188755Z","shell.execute_reply.started":"2021-09-21T04:43:25.799421Z","shell.execute_reply":"2021-09-21T04:43:26.18799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def denorm(img_tensors):\n    return img_tensors * stats[1][0] + stats[0][0]","metadata":{"execution":{"iopub.status.busy":"2021-09-21T04:43:26.194008Z","iopub.execute_input":"2021-09-21T04:43:26.194259Z","iopub.status.idle":"2021-09-21T04:43:26.201028Z","shell.execute_reply.started":"2021-09-21T04:43:26.194234Z","shell.execute_reply":"2021-09-21T04:43:26.200051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This part does the task of plotting.","metadata":{}},{"cell_type":"code","source":"def show_images(images, nmax=64):\n    fig, ax = plt.subplots(figsize=(8, 8))\n    ax.set_xticks([]); ax.set_yticks([])\n    ax.imshow(make_grid(denorm(images.detach()[:nmax]), nrow=8).permute(1, 2, 0))","metadata":{"execution":{"iopub.status.busy":"2021-09-21T04:43:26.205033Z","iopub.execute_input":"2021-09-21T04:43:26.205286Z","iopub.status.idle":"2021-09-21T04:43:26.213358Z","shell.execute_reply.started":"2021-09-21T04:43:26.205262Z","shell.execute_reply":"2021-09-21T04:43:26.212533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_batch(dl, nmax=64):\n    for images, _ in dl:\n        show_images(images, nmax)\n        break","metadata":{"execution":{"iopub.status.busy":"2021-09-21T04:43:26.216113Z","iopub.execute_input":"2021-09-21T04:43:26.216351Z","iopub.status.idle":"2021-09-21T04:43:26.222782Z","shell.execute_reply.started":"2021-09-21T04:43:26.216327Z","shell.execute_reply":"2021-09-21T04:43:26.221976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_batch(train_dl)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T04:43:26.224151Z","iopub.execute_input":"2021-09-21T04:43:26.22454Z","iopub.status.idle":"2021-09-21T04:43:31.425259Z","shell.execute_reply.started":"2021-09-21T04:43:26.224503Z","shell.execute_reply":"2021-09-21T04:43:31.420727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This block checks if the cuda is enabled to take advantage of the gpu. Otherwise it will run the code on cpu. This code creates the dataloader for the device as well.","metadata":{}},{"cell_type":"code","source":"def get_default_device():\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n\ndef to_device(data,device):\n    if isinstance(data,(list,tuple)):\n        return [to_device(x,device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    def __init__(self,dl,device):\n        self.dl = dl\n        self.device = device\n    def __iter__(self):\n        for b in self.dl:\n            yield to_device(b,device)\n    def __len__(self):\n        return len(self.dl)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T04:43:31.426663Z","iopub.execute_input":"2021-09-21T04:43:31.427007Z","iopub.status.idle":"2021-09-21T04:43:31.436635Z","shell.execute_reply.started":"2021-09-21T04:43:31.42697Z","shell.execute_reply":"2021-09-21T04:43:31.435722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = get_default_device()\ndevice","metadata":{"execution":{"iopub.status.busy":"2021-09-21T04:43:31.438418Z","iopub.execute_input":"2021-09-21T04:43:31.439072Z","iopub.status.idle":"2021-09-21T04:43:31.448561Z","shell.execute_reply.started":"2021-09-21T04:43:31.439032Z","shell.execute_reply":"2021-09-21T04:43:31.447615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This code sends the train dataloader to the device(cuda/cpu). ","metadata":{}},{"cell_type":"code","source":"train_dl = DeviceDataLoader(train_dl, device)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T04:43:31.450121Z","iopub.execute_input":"2021-09-21T04:43:31.450596Z","iopub.status.idle":"2021-09-21T04:43:31.45556Z","shell.execute_reply.started":"2021-09-21T04:43:31.450558Z","shell.execute_reply":"2021-09-21T04:43:31.454594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This is the core of our tutorial. This is block where the model has been built.Since GAN has basically two networks--Discriminator and Generator. This block builds the discriminator network.As we can see from the code basically there are repeated use of three layers which constitue a single block.If we observe the block carefully,first there is a convolution layer which extracts low level details from the image. And then batchnormalization is applied.For activation function,leakyrelu is applied.In the last layer,we have flattened the tensors and passed them through the sigmoid activation layer.","metadata":{}},{"cell_type":"code","source":"discriminator = nn.Sequential(\n    nn.Conv2d(3,64,kernel_size=4,stride=2,padding=1,bias=False),\n    nn.BatchNorm2d(64),\n    nn.LeakyReLU(0.2,inplace=True),\n    \n    \n    nn.Conv2d(64,128,kernel_size=4,stride=2,padding=1,bias=False),\n    nn.BatchNorm2d(128),\n    nn.LeakyReLU(0.2,inplace=True),\n    \n    nn.Conv2d(128,256,kernel_size=4,stride=2,padding=1,bias=False),\n    nn.BatchNorm2d(256),\n    nn.LeakyReLU(0.2,inplace=True),\n    \n    nn.Conv2d(256,512,kernel_size=4,stride=2,padding=1,bias=False),\n    nn.BatchNorm2d(512),\n    nn.LeakyReLU(0.2,inplace=True),\n    \n    nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=0, bias=False),\n    \n    nn.Flatten(),\n    nn.Sigmoid()\n)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T04:43:31.457168Z","iopub.execute_input":"2021-09-21T04:43:31.457719Z","iopub.status.idle":"2021-09-21T04:43:31.489164Z","shell.execute_reply.started":"2021-09-21T04:43:31.457662Z","shell.execute_reply":"2021-09-21T04:43:31.488394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"discriminator = to_device(discriminator,device)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T04:43:31.4903Z","iopub.execute_input":"2021-09-21T04:43:31.490639Z","iopub.status.idle":"2021-09-21T04:43:31.502174Z","shell.execute_reply.started":"2021-09-21T04:43:31.490605Z","shell.execute_reply":"2021-09-21T04:43:31.501538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We have used a latent size of 128. Here is the generator block which consists of transposed convolutional layer. And then batch normalization is used.For activation function,Relu is used which is different from discriminator network. Finally,at the end of the generator block,tanh activation layer is applied.","metadata":{}},{"cell_type":"code","source":"latent_size = 128\ngenerator = nn.Sequential(\n    nn.ConvTranspose2d(latent_size,512,kernel_size=4,stride=1,padding=0,bias = False),\n    nn.BatchNorm2d(512),\n    nn.ReLU(True),\n    \n    nn.ConvTranspose2d(512,256,kernel_size=4,stride=2,padding=1,bias = False),\n    nn.BatchNorm2d(256),\n    nn.ReLU(True),\n    \n    nn.ConvTranspose2d(256,128,kernel_size=4,stride=2,padding=1,bias = False),\n    nn.BatchNorm2d(128),\n    nn.ReLU(True),\n    \n    nn.ConvTranspose2d(128,64,kernel_size=4,stride=2,padding=1,bias = False),\n    nn.BatchNorm2d(64),\n    nn.ReLU(True),\n    \n    nn.ConvTranspose2d(64,3,kernel_size=4,stride=2,padding=1,bias = False),\n    nn.Tanh()\n)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T04:43:31.503469Z","iopub.execute_input":"2021-09-21T04:43:31.503826Z","iopub.status.idle":"2021-09-21T04:43:31.538011Z","shell.execute_reply.started":"2021-09-21T04:43:31.503791Z","shell.execute_reply":"2021-09-21T04:43:31.537237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In this block,we have tested the generator block with some random latent tensors.The main goal of this block is to see whether the generator works or not. And the main task of the generator is to produce fake images.","metadata":{}},{"cell_type":"code","source":"xb = torch.randn(batch_size, latent_size, 1, 1) # random latent tensors\nfake_images = generator(xb)\nprint(fake_images.shape)\nshow_images(fake_images)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T04:43:31.539191Z","iopub.execute_input":"2021-09-21T04:43:31.53953Z","iopub.status.idle":"2021-09-21T04:43:32.144321Z","shell.execute_reply.started":"2021-09-21T04:43:31.539496Z","shell.execute_reply":"2021-09-21T04:43:32.143518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator = to_device(generator,device)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T04:43:32.145729Z","iopub.execute_input":"2021-09-21T04:43:32.146271Z","iopub.status.idle":"2021-09-21T04:43:32.164059Z","shell.execute_reply.started":"2021-09-21T04:43:32.146232Z","shell.execute_reply":"2021-09-21T04:43:32.156134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This part is the cream of this tutorial where we wll perform the training of this GAN model.Eventually,we will train the discriminator first.For that,we will first clear the gradient of the discriminator network,which is basically initialize the discriminator network with zero weight. And then real images are passed through this.The main task of the discriminator is to distinguish the real images from the fake ones,generated from the generator network.To be precise, we will try to minimize the loss function of the discriminator net. For the loss function, we have used binary cross-entropy to calculate the loss between real and fake images. Proceeding forward, we observe that fake images are passed through this net to calculate fake loss. In the end,both fake and real loss are summed to calculated the total loss.This loss will be used in the backpropagation phase to update the weight of the discriminator network.And this is done in the last part of this block. Finally this block will output some real scores and fake scores.","metadata":{}},{"cell_type":"code","source":"def train_discriminator(real_images, opt_d):\n    # Clear discriminator gradients\n    opt_d.zero_grad()\n\n    # Pass real images through discriminator\n    real_preds = discriminator(real_images)\n    real_targets = torch.ones(real_images.size(0), 1, device=device)\n    real_loss = F.binary_cross_entropy(real_preds, real_targets)\n    real_score = torch.mean(real_preds).item()\n    \n    # Generate fake images\n    latent = torch.randn(batch_size, latent_size, 1, 1, device=device)\n    fake_images = generator(latent)\n\n    # Pass fake images through discriminator\n    fake_targets = torch.zeros(fake_images.size(0), 1, device=device)\n    fake_preds = discriminator(fake_images)\n    fake_loss = F.binary_cross_entropy(fake_preds, fake_targets)\n    fake_score = torch.mean(fake_preds).item()\n\n    # Update discriminator weights\n    loss = real_loss + fake_loss\n    loss.backward()\n    opt_d.step()\n    return loss.item(), real_score, fake_score","metadata":{"execution":{"iopub.status.busy":"2021-09-21T04:43:32.16519Z","iopub.execute_input":"2021-09-21T04:43:32.165649Z","iopub.status.idle":"2021-09-21T04:43:32.184255Z","shell.execute_reply.started":"2021-09-21T04:43:32.165603Z","shell.execute_reply":"2021-09-21T04:43:32.183137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This block is pretty similar to the block explained above.Here we are training the generator network.The generator network will basically train through the discriminator network. The goal of the generator network is to produce fake images to fool the discriminator. Its like a competition going between generator and discriminator.Through this game, the loss function of both the network will come into an equilibrium point when the generator will learn to produce images which will look perfectly like real ones.Just like the discriminator network,this net will update its weights through loss function.","metadata":{}},{"cell_type":"code","source":"def train_generator(opt):\n    opt.zero_grad()\n    latent = torch.randn(batch_size,latent_size,1,1,device=device)\n    fake_images = generator(latent)\n    preds = discriminator(fake_images)\n    targets = torch.ones(batch_size,1,device = device)\n    loss = F.binary_cross_entropy(preds,targets)\n    loss.backward()\n    opt.step()\n    return loss.item()\n    ","metadata":{"execution":{"iopub.status.busy":"2021-09-21T04:43:32.185988Z","iopub.execute_input":"2021-09-21T04:43:32.186659Z","iopub.status.idle":"2021-09-21T04:43:32.201732Z","shell.execute_reply.started":"2021-09-21T04:43:32.186617Z","shell.execute_reply":"2021-09-21T04:43:32.200737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_dir = 'generated'\nos.makedirs(sample_dir, exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T04:43:32.204602Z","iopub.execute_input":"2021-09-21T04:43:32.206432Z","iopub.status.idle":"2021-09-21T04:43:32.214377Z","shell.execute_reply.started":"2021-09-21T04:43:32.206391Z","shell.execute_reply":"2021-09-21T04:43:32.21342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In this block, we will save the images generated from the generator network.In the end, we will plot them to compare with the real images.","metadata":{}},{"cell_type":"code","source":"def save_samples(index, latent_tensors, show=True):\n    fake_images = generator(latent_tensors)\n    fake_fname = 'generated-images-{0:0=4d}.png'.format(index)\n    save_image(denorm(fake_images), os.path.join(sample_dir, fake_fname), nrow=8)\n    print('Saving', fake_fname)\n    if show:\n        fig, ax = plt.subplots(figsize=(8, 8))\n        ax.set_xticks([]); ax.set_yticks([])\n        ax.imshow(make_grid(fake_images.cpu().detach(), nrow=8).permute(1, 2, 0))","metadata":{"execution":{"iopub.status.busy":"2021-09-21T04:43:32.217003Z","iopub.execute_input":"2021-09-21T04:43:32.218111Z","iopub.status.idle":"2021-09-21T04:43:32.230332Z","shell.execute_reply.started":"2021-09-21T04:43:32.218073Z","shell.execute_reply":"2021-09-21T04:43:32.229317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fixed_latent = torch.randn(64, latent_size, 1, 1, device=device)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T04:43:32.231883Z","iopub.execute_input":"2021-09-21T04:43:32.232589Z","iopub.status.idle":"2021-09-21T04:43:32.242362Z","shell.execute_reply.started":"2021-09-21T04:43:32.23255Z","shell.execute_reply":"2021-09-21T04:43:32.241235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save_samples(0, fixed_latent)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T04:43:32.244648Z","iopub.execute_input":"2021-09-21T04:43:32.247177Z","iopub.status.idle":"2021-09-21T04:43:33.057756Z","shell.execute_reply.started":"2021-09-21T04:43:32.247125Z","shell.execute_reply":"2021-09-21T04:43:33.056881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This block defines the setting of the training of the GAN networks.Indeed this is the lock, where will define the hyperparameters of the trainig like the optmizer.In respect of this,we will use Adam optimizer for both of our networks.Besides,here will calculate all the relevant scores of the network. ","metadata":{}},{"cell_type":"code","source":"def fit(epochs, lr, start_idx=1):\n    torch.cuda.empty_cache()\n    \n    # Losses & scores\n    losses_g = []\n    losses_d = []\n    real_scores = []\n    fake_scores = []\n    \n    # Create optimizers\n    opt_d = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n    opt_g = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n    \n    for epoch in range(epochs):\n        for real_images, _ in tqdm(train_dl):\n            # Train discriminator\n            loss_d, real_score, fake_score = train_discriminator(real_images, opt_d)\n            # Train generator\n            loss_g = train_generator(opt_g)\n            \n        # Record losses & scores\n        losses_g.append(loss_g)\n        losses_d.append(loss_d)\n        real_scores.append(real_score)\n        fake_scores.append(fake_score)\n        \n        # Log losses & scores (last batch)\n        print(\"Epoch [{}/{}], loss_g: {:.4f}, loss_d: {:.4f}, real_score: {:.4f}, fake_score: {:.4f}\".format(\n            epoch+1, epochs, loss_g, loss_d, real_score, fake_score))\n    \n        # Save generated images\n        save_samples(epoch+start_idx, fixed_latent, show=False)\n    \n    return losses_g, losses_d, real_scores, fake_scores","metadata":{"execution":{"iopub.status.busy":"2021-09-21T04:43:33.059059Z","iopub.execute_input":"2021-09-21T04:43:33.059576Z","iopub.status.idle":"2021-09-21T04:43:33.074312Z","shell.execute_reply.started":"2021-09-21T04:43:33.059533Z","shell.execute_reply":"2021-09-21T04:43:33.073358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This block defines two very important hyperparameters--learning rate and epoch.And finally, we will fit the netowrk/train the netowork here.After the execution of this block,we will get our loss scores to see the performance of our designed model.","metadata":{}},{"cell_type":"code","source":"lr = 0.0002\nepochs = 500\nhistory = fit(epochs, lr)","metadata":{"execution":{"iopub.status.busy":"2021-09-21T04:43:33.075757Z","iopub.execute_input":"2021-09-21T04:43:33.076399Z","iopub.status.idle":"2021-09-21T04:49:30.200864Z","shell.execute_reply.started":"2021-09-21T04:43:33.076361Z","shell.execute_reply":"2021-09-21T04:49:30.1983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"losses_g, losses_d, real_scores, fake_scores = history","metadata":{"execution":{"iopub.status.busy":"2021-09-21T04:49:30.20248Z","iopub.status.idle":"2021-09-21T04:49:30.203237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import Image\nImage('./generated/generated-images-0184.png')\n","metadata":{"execution":{"iopub.status.busy":"2021-09-21T04:49:30.204795Z","iopub.status.idle":"2021-09-21T04:49:30.205591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The last two blocks involve the plotting of the \"Epoch-loss\" as well as \"Epoch--score/accuracy\" curve. ","metadata":{}},{"cell_type":"code","source":"plt.plot(losses_d, '-')\nplt.plot(losses_g, '-')\nplt.xlabel('epoch')\nplt.ylabel('loss')\nplt.legend(['Discriminator', 'Generator'])\nplt.title('Losses');","metadata":{"execution":{"iopub.status.busy":"2021-09-21T04:49:30.209095Z","iopub.status.idle":"2021-09-21T04:49:30.209859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(real_scores, '-')\nplt.plot(fake_scores, '-')\nplt.xlabel('epoch')\nplt.ylabel('score')\nplt.legend(['Real', 'Fake'])\nplt.title('Scores');","metadata":{"execution":{"iopub.status.busy":"2021-09-21T04:49:30.211214Z","iopub.status.idle":"2021-09-21T04:49:30.211928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So finally we have found the plot fake vs real images ! \n\nThank you.\n[References](https://www.kaggle.com/ibtesama/generative-adversarial-networks-demystified)","metadata":{}}]}