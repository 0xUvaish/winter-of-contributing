{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **<ins>Classical CNNs - AlexNet, VGGNet</ins>**\n",
    "**Type of Content** : Documentation\n",
    "\n",
    "**Domain** : Machine Learning\n",
    "\n",
    "**Module** : ML for Seqential Data & Visual Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN\n",
    "The Convolutional neural networks(ConvNet/CNN) are regularized versions of multilayer perceptron (MLP). They were developed based on the working of the neurons of the animal visual cortex.<br>\n",
    "It is a Deep Learning algorithm which can take in an input image, assign importance (learnable weights and biases) to various aspects/objects in the image and be able to differentiate one from the other. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    <img src=\"https://miro.medium.com/max/2000/1*vkQ0hXDaQv57sALXAJquxA.jpeg\" style=\"width:80%\">\n",
    "    <figcaption style=\"text-align: center\">Classic CNN Architecture</figcaption>\n",
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are various architectures of CNNs available which have been key in building algorithms which power AI as a whole in the foreseeable future. AlexNet and VGGNet are one of them.\n",
    "\n",
    "## AlexNet\n",
    "The Alexnet has eight layers with learnable parameters: five convolutional layers and three fully-connected layers. Some features of AlexNet are as follows:\n",
    "- <b>ReLU Non-linearity:</b> AlexNet uses Rectified Linear Units (ReLU) instead of the Tanh function, which was standard at the time. ReLU’s advantage is in training time; a CNN using ReLU was able to reach a 25% error on the CIFAR-10 dataset six times faster than a CNN using Tanh.\n",
    "- <b>Training on Multiple GPUs:</b> AlexNet allows for multi-GPU training by putting half of the model’s neurons on one GPU and the other half on another GPU. Not only does this mean that a bigger model can be trained, but it also cuts down on the training time.\n",
    "- <b>Local Response Normalization:</b> Response normalization reduces the top-1 and top-5 error rates by 1.4% and 1.2%, respectively. The effectiveness of this scheme was also verified on the CIFAR-10 dataset: a four-layer CNN achieved a 13% test error rate without normalization and 11% with normalization\n",
    "- <b>Overlapping Pooling:</b> CNNs traditionally “pool” outputs of neighboring groups of neurons with no overlapping. However, when the authors introduced overlap, they saw a reduction in error by about 0.5% and found that models with overlapping pooling generally find it harder to overfit.\n",
    "- <b>Overall Architecture:</b> The network maximizes the multinomial logistic regression objective, which is equivalent to maximizing the average across training cases of the log-probability of the correct label under the prediction distribution.\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1124/1*5bnqbGcBSLzaNMsz5dHkfg.png\" style=\"width:90%\">\n",
    "<figcaption style=\"text-align: center\">AlexNet's Architecture Illustration</figcaption>\n",
    "\n",
    "The kernels of the second, fourth, and fifth convolutional layers are connected only to those kernel\n",
    "maps in the previous layer which reside on the same GPU. The kernels of the third convolutional layer are connected to all kernel maps in the second layer. The neurons in the fullyconnected layers are connected to all neurons in the previous layer. Response-normalization layers follow the first and second convolutional layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing Overfitting\n",
    "AlexNet has 60 million parameters; and it turned out that 1000 classes of ILSVRC were insufficient to learn these parameters without overfitting. Following are the two primary ways which are used to overcome overfitting problem:\n",
    "- <b>Data Augmentation</b>: They used label-preserving transformation to make their data more varied. Specifically, they generated image translations and horizontal reflections, which increased the training set by a factor of 2048. They also performed Principle Component Analysis (PCA) on the RGB pixel values to change the intensities of RGB channels, which reduced the top-1 error rate by more than 1%.\n",
    "- <b>Dropout</b>: It consists of setting to zero the output of each hidden neuron with probability 0.5. The neurons which are “dropped out” in this way do not contribute to the forward pass and do not participate in backpropagation. So every time an input is presented, the neural network samples a different architecture, but all these architectures share weights. This technique reduces complex co-adaptations of neurons, since a neuron cannot rely on the presence of particular other neurons. \n",
    "\n",
    "### Conclusion\n",
    "AlexNet is an incredibly powerful model capable of achieving high accuracies on very challenging datasets. However, removing any of the convolutional layers will drastically degrade AlexNet’s performance. AlexNet is a leading architecture for any object-detection task and may have huge applications in the computer vision sector of artificial intelligence problems. In the future, AlexNet may be adopted more than CNNs for image tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGGNet\n",
    "VGG is a convolutional neural network model proposed by K. Simonyan and A. Zisserman from the University of Oxford in the paper “Very Deep Convolutional Networks for Large-Scale Image Recognition”  . The model achieves 92.7% top-5 test accuracy in ImageNet, which is a dataset of over 14 million images belonging to 1000 classes.\n",
    "\n",
    "### Architecture\n",
    "\n",
    "This is the architecture map of VGGNet:\n",
    "<img src=\"https://neurohive.io/wp-content/uploads/2018/11/vgg16.png\" style=\"width:80%\">\n",
    "It makes the improvement over AlexNet by replacing large kernel-sized filters (11 and 5 in the first and second convolutional layer, respectively) with multiple 3×3 kernel-sized filters one after another. VGG16 was trained for weeks and was using NVIDIA Titan Black GPU’s.\n",
    "\n",
    "The input to cov1 layer is of fixed size 224 x 224 RGB image. The image is passed through a stack of convolutional (conv.) layers, where the filters were used with a very small receptive field: 3×3 (which is the smallest size to capture the notion of left/right, up/down, center). \n",
    "\n",
    "In one of the configurations, it also utilizes 1×1 convolution filters, which can be seen as a linear transformation of the input channels (followed by non-linearity). The convolution stride is fixed to 1 pixel; the spatial padding of conv. layer input is such that the spatial resolution is preserved after convolution, i.e. the padding is 1-pixel for 3×3 conv. layers.<br>\n",
    "<img src=\"https://neurohive.io/wp-content/uploads/2018/11/vgg16-1-e1542731207177.png\" style=\"width:70%\">\n",
    "<figcaption style=\"text-align: center\">VGGNet's Architecture Illustration</figcaption>\n",
    "\n",
    "Spatial pooling is carried out by five max-pooling layers, which follow some of the conv. layers (not all of them are followed by max-pooling). Max-pooling is performed over a 2×2 pixel window, with stride 2.\n",
    "\n",
    "Three Fully-Connected (FC) layers follow a stack of convolutional layers (which has a different depth in different architectures): the first two have 4096 channels each, the third performs 1000-way ILSVRC classification and thus contains 1000 channels (one for each class). The final layer is the soft-max layer. The configuration of the fully connected layers is the same in all networks.\n",
    "\n",
    "All hidden layers are equipped with the rectification (ReLU) non-linearity. It is also noted that none of the networks (except for one) contain Local Response Normalisation (LRN), such normalization does not improve the performance on the ILSVRC dataset, but leads to increased memory consumption and computation time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "VGG16 significantly outperforms the previous generation of models in the ILSVRC-2012 and ILSVRC-2013 competitions. VGG-16 was one of the best performing architecture in ILSVRC challenge 2014.It was the runner up in classification task with top-5 classification error of 7.32% (only behind GoogLeNet with classification error 6.66%). It was also the winner of localization task with 25.32% localization error. VGG16 significantly outperforms the previous generation of models in the ILSVRC-2012 and ILSVRC-2013 competitions.\n",
    "\n",
    "### Challenges Of VGG 16\n",
    "Unfortunately, there are two major drawbacks with VGGNet:\n",
    "- It is very slow to train (the original VGG model was trained on Nvidia Titan GPU for 2-3 weeks).\n",
    "- The size of VGG-16 trained imageNet weights is 528 MB. So, it takes quite a lot of disk space and bandwidth that makes it inefficient.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "- https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf\n",
    "- https://arxiv.org/pdf/1409.1556.pdf\n",
    "- https://www.geeksforgeeks.org/vgg-16-cnn-model/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
