{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_8_11_ResNet_(D).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pN4X5NqyBycY"
      },
      "source": [
        "# **ResNet**\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/1050/1*S4n857wx4hRv20Lmhn_uNQ.jpeg\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfCwqriDB3ew"
      },
      "source": [
        "## **What is ResNet?**\n",
        "ResNet, short for Residual Network is a specific type of neural network that was introduced in 2015 by Kaiming He, Xiangyu Zhang, Shaoqing Ren and Jian Sun in their paper “Deep Residual Learning for Image Recognition”.\n",
        "\n",
        "<br>\n",
        "\n",
        "##**How ResNet helps**\n",
        "\n",
        "The skip connections in ResNet solve the problem of vanishing gradient in deep neural networks by allowing this alternate shortcut path for the gradient to flow through. The other way that these connections help is by allowing the model to learn the identity functions which ensures that the higher layer will perform at least as good as the lower layer, and not worse. \n",
        "\n",
        "## **What is Residual Blocks ?**\n",
        "The problem of training very deep networks has been relieved with the introduction of these Residual blocks and the ResNet model is made up of these blocks.\n",
        "\n",
        "The problem of training very deep networks has been relieved with the introduction of these Residual blocks and the ResNet model is made up of these blocks.\n",
        "\n",
        "<br>\n",
        "\n",
        "<img src=\"https://neurohive.io/wp-content/uploads/2019/01/resnet-e1548261477164.png\">\n",
        " \n",
        " <br>\n",
        "\n",
        "The very first thing that is noticed to be different is that there is a direct connection which skips some layers(may vary in different models) in between. This connection is called ’skip connection’ and is the core of residual blocks. Due to this skip connection, the output of the layer is not the same now. Without using this skip connection, the input ‘x’ gets multiplied by the weights of the layer followed by adding a bias term.\n",
        "\n",
        "Then comes the activation function, f() and we get the output as H(x).\n",
        "\n",
        "**H(x)=f( wx + b ) or H(x)=f(x)**\n",
        "\n",
        "Now with the introduction of a new skip connection technique, the output is H(x) is changed to\n",
        "\n",
        "**H(x)=f(x)+x**\n",
        "\n",
        "\n",
        "There appears to be a slight problem with this approach when the dimensions of the input vary from that of the output which can happen with convolutional and pooling layers. In this case, when dimensions of f(x) are different from x, we can take two approaches:\n",
        "\n",
        "* The skip connection is padded with extra zero entries to increase its dimensions.\n",
        "* The projection method is used to match the dimension which is done by adding 1×1 convolutional layers to input. In such a case, the output is: **H(x)=f(x)+w1.x**\n",
        "\n",
        "Here we add an additional parameter w1 whereas no additional parameter is added when using the first approach."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYku5RKAGQTp"
      },
      "source": [
        "## **ResNet architecture**\n",
        "\n",
        "There is a 34-layer plain network in the architecture that is inspired by VGG-19 in which the shortcut connection or the skip connections are added. These skip connections or the residual blocks then convert the architecture into the residual network as shown in the figure below.\n",
        "\n",
        "<br>\n",
        "<img src=\"https://editor.analyticsvidhya.com/uploads/28984n2.png\">\n",
        "\n",
        "##**Using ResNet with Keras**\n",
        "\n",
        "Keras is an open-source neural network library written in Python which is capable of running on top of TensorFlow, Microsoft Cognitive Toolkit, R, Theano, or PlaidML. It is designed to enable fast experimentation with deep neural networks. Keras Applications include the following ResNet implementations and provide ResNet V1 and ResNet V2 with 50, 101, or 152 layers\n",
        "\n",
        "* ResNet50 \n",
        "* ResNet101 \n",
        "* ResNet152 \n",
        "* ResNet50V2 \n",
        "* ResNet101V2 \n",
        "* ResNet152V2 \n",
        "\n",
        "The primary difference between ResNetV2 and the original (V1) is that V2 uses batch normalization before each weight layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ns12Mue-Hiua"
      },
      "source": [
        "##**Implementation**\n",
        "\n",
        "ResNet architecture uses the CNN blocks multiple times, so let us create a class for CNN block, which takes input channels and output channels. There is a batchnorm2d after each conv layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyK0D_POIRvR"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class block(nn.Module):\n",
        "    def __init__(\n",
        "        self, in_channels, intermediate_channels, identity_downsample=None, stride=1\n",
        "    ):\n",
        "        super(block, self).__init__()\n",
        "        self.expansion = 4\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels, intermediate_channels, kernel_size=1, stride=1, padding=0, bias=False\n",
        "        )\n",
        "        self.bn1 = nn.BatchNorm2d(intermediate_channels)\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            intermediate_channels,\n",
        "            intermediate_channels,\n",
        "            kernel_size=3,\n",
        "            stride=stride,\n",
        "            padding=1,\n",
        "            bias=False\n",
        "        )\n",
        "        self.bn2 = nn.BatchNorm2d(intermediate_channels)\n",
        "        self.conv3 = nn.Conv2d(\n",
        "            intermediate_channels,\n",
        "            intermediate_channels * self.expansion,\n",
        "            kernel_size=1,\n",
        "            stride=1,\n",
        "            padding=0,\n",
        "            bias=False\n",
        "        )\n",
        "        self.bn3 = nn.BatchNorm2d(intermediate_channels * self.expansion)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.identity_downsample = identity_downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x.clone()\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "\n",
        "        if self.identity_downsample is not None:\n",
        "            identity = self.identity_downsample(identity)\n",
        "\n",
        "        x += identity\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, layers, image_channels, num_classes):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_channels = 64\n",
        "        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        # Essentially the entire ResNet architecture are in these 4 lines below\n",
        "        self.layer1 = self._make_layer(\n",
        "            block, layers[0], intermediate_channels=64, stride=1\n",
        "        )\n",
        "        self.layer2 = self._make_layer(\n",
        "            block, layers[1], intermediate_channels=128, stride=2\n",
        "        )\n",
        "        self.layer3 = self._make_layer(\n",
        "            block, layers[2], intermediate_channels=256, stride=2\n",
        "        )\n",
        "        self.layer4 = self._make_layer(\n",
        "            block, layers[3], intermediate_channels=512, stride=2\n",
        "        )\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512 * 4, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def _make_layer(self, block, num_residual_blocks, intermediate_channels, stride):\n",
        "        identity_downsample = None\n",
        "        layers = []\n",
        "\n",
        "        # Either if we half the input space for ex, 56x56 -> 28x28 (stride=2), or channels changes\n",
        "        # we need to adapt the Identity (skip connection) so it will be able to be added\n",
        "        # to the layer that's ahead\n",
        "        if stride != 1 or self.in_channels != intermediate_channels * 4:\n",
        "            identity_downsample = nn.Sequential(\n",
        "                nn.Conv2d(\n",
        "                    self.in_channels,\n",
        "                    intermediate_channels * 4,\n",
        "                    kernel_size=1,\n",
        "                    stride=stride,\n",
        "                    bias=False\n",
        "                ),\n",
        "                nn.BatchNorm2d(intermediate_channels * 4),\n",
        "            )\n",
        "\n",
        "        layers.append(\n",
        "            block(self.in_channels, intermediate_channels, identity_downsample, stride)\n",
        "        )\n",
        "\n",
        "        # The expansion size is always 4 for ResNet 50,101,152\n",
        "        self.in_channels = intermediate_channels * 4\n",
        "\n",
        "        # For example for first resnet layer: 256 will be mapped to 64 as intermediate layer,\n",
        "        # then finally back to 256. Hence no identity downsample is needed, since stride = 1,\n",
        "        # and also same amount of channels.\n",
        "        for i in range(num_residual_blocks - 1):\n",
        "            layers.append(block(self.in_channels, intermediate_channels))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "def ResNet50(img_channel=3, num_classes=1000):\n",
        "    return ResNet(block, [3, 4, 6, 3], img_channel, num_classes)\n",
        "\n",
        "\n",
        "def ResNet101(img_channel=3, num_classes=1000):\n",
        "    return ResNet(block, [3, 4, 23, 3], img_channel, num_classes)\n",
        "\n",
        "\n",
        "def ResNet152(img_channel=3, num_classes=1000):\n",
        "    return ResNet(block, [3, 8, 36, 3], img_channel, num_classes)\n",
        "\n",
        "\n",
        "def test():\n",
        "    net = ResNet101(img_channel=3, num_classes=1000)\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    y = net(torch.randn(4, 3, 224, 224)).to(device)\n",
        "    print(y.size())\n",
        "\n",
        "\n",
        "test()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YP-zr_GOIw5_"
      },
      "source": [
        "* Here ResNet class takes the input of a number of blocks, layers, image channels, and the number of classes.\n",
        "* the function ‘_make_layer’\n",
        "creates the ResNet layers, which takes the input of blocks, number of residual\n",
        "blocks, out channel, and strides.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFDkhmkkJY1S"
      },
      "source": [
        "###**Conclusion**\n",
        "\n",
        "Hence in this Documentation I have briefed about basic knowledge on ResNet.Hope it gave you a thorough understanding !\n",
        "\n",
        "thanks for reading !\n",
        "\n",
        "###**References**\n",
        "\n",
        "https://www.geeksforgeeks.org/residual-networks-resnet-deep-learning/?ref=lbp\n",
        "\n",
        "https://medium.com/swlh/resnet-a-simple-understanding-of-the-residual-networks-bfd8a1b4a447"
      ]
    }
  ]
}