{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_8_19_GAN(D).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8BNZjj-xqom"
      },
      "source": [
        "# **Generative Adversarial Networks**\n",
        "<hr>\n",
        "\n",
        "So, to get ourselves excited for this really cool Machine Learning technique GANs, lets look at some of the demos.\n",
        "<br><br>\n",
        "\n",
        "1. **Image Uncropping** : \n",
        "\n",
        "  This is Project Boundless by Google's Machine Perception. In this project, the team solves the task of image of uncropping. Image uncropping is like, it tries to extend the borders of the images in a plausible way, that image as a whole looks like a real image. \n",
        "\n",
        "  To give you a gist, below are the 2 images before and after applying GANs technique.\n",
        "\n",
        "  #### **Before**\n",
        "  ![Before](https://drive.google.com/uc?id=1lkdIniDbe2czNnwMW4Ma5s4kNDC6tz5k)\n",
        "\n",
        "\n",
        "#### **After**\n",
        "\n",
        "![After](https://drive.google.com/uc?id=1u2R291-qP_BJqa3jqVbC82DHpVIOX1iR)\n",
        "\n",
        "As you can see in the above image it has wider frame then the previous image, and this is what is called image uncropping, where as we can see the extended border of the image.\n",
        "<br><br>\n",
        "\n",
        "![After](https://drive.google.com/uc?id=16rsbCLRkTtBD6qmhJiZeV4eLtkZB8nyQ)\n",
        "\n",
        "The blue lines that we are seeing in the above image, the image past these borders has been created with the help of GANs.\n",
        "<br><br>\n",
        "\n",
        "#### **Video of the Example**\n",
        "\n",
        "Below, is the video shoot by the team with the help of drone, is an example of thier algorithm expanding the image in a plausible way.\n",
        "\n",
        "[![Video](https://drive.google.com/uc?id=1u2R291-qP_BJqa3jqVbC82DHpVIOX1iR)](https://www.youtube.com/watch?v=P2Opq3urYwo)\n",
        "\n",
        "> **Credit for images above => Tenserflow**\n",
        "\n",
        "<br><br>\n",
        "\n",
        "2. **Generating Musical Notes**\n",
        "\n",
        "  This is another cool project, comes from another team from Google known as Magenta Team. And the name of the project is **Project GANSynth**.  \n",
        "  The task of this project is entirely different from the previous one. The goal of this project was to produce realistic sounding musical notes from musical files. The algorithm is not actually composing music, but instead it is trying to create a rich perceptual texture that we often get from musical instruments.\n",
        "\n",
        "  And lets listen to audio that they have created and to get the sense what actually they have created.\n",
        "\n",
        "  And try to listen closely, to sense what kind of quality they have actually managed to acheive.\n",
        "\n",
        "  [![Audio](https://drive.google.com/uc?id=1tQA2V6pmSwka4d5J1CB4OLZUI_d1vsSG)](https://storage.googleapis.com/magentadata/papers/gansynth/consistent_timbre/bach_single_latent_vector.mp3)\n",
        "\n",
        "  As compared to some other previous systems, this system was able to recreate more realistic and pleasing sound.\n",
        "\n",
        "  The second task that system was able to complete was to smoothly interpolate between different instruments. In this task a feature of GANs is used which is latent space. Latent space is the sort of space, that helps the system to generate a large number of samples.\n",
        "\n",
        "  So, without further ado lets hear this audio. In this audio we will onserve how smoothly the music changes from one instrument to another.\n",
        "\n",
        "    [![Audio](https://drive.google.com/uc?id=1JnMZI895ipg_uOeKiAKtT695RHBvHBMH)](https://storage.googleapis.com/magentadata/papers/gansynth/interpolations/bach_interpolated.mp3)\n",
        "\n",
        "  \n",
        ">So, I am posting the public link of their work, and if you are interested, I strongly recommend you to go throught their work, and have more insight about it.  \n",
        "<br>\n",
        "**Link** => [GANSynth](https://storage.googleapis.com/magentadata/papers/gansynth/index.html)\n",
        "  \n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "So, maybe I hopefully got you excited about GANs. So, without further ado, lets start by having some brief introduction about GANs.\n",
        "\n",
        "## **What is GANs ?**\n",
        "\n",
        "Generative adversarial networks (GANs) are an exciting recent advancement in artificial intelligence because of its ability to generate new things. GANs are generative models: they create new data instances based on the training data we feed them. The data they create is entirely new but it resembles the to the training data. For example, GANs can create images that look like photographs of human faces, even though the faces don't belong to any real person. As you have already seen in the above demos, where GANs are used to extend the border of the image and also create some musical notes based on the data feeded to it.\n",
        "\n",
        "It is a machine learning (ML) model in which two neural networks pits against each other to generate more realistic looking data. These two neural networs are: generator and discriminator.\n",
        "\n",
        "The generator and discriminator, both gets trained in alternating cycles.During the training, the generator learns to produce more and more realistic looking data, while discriminator on the other side, get better and better on differentiating real data from the newly generated data by the generator. In a more simple language, we can say that generator always tries to fool discriminator, whereas discriminator tries to not get fooled, and the time when discriminator no longer distinguish between real data and the data created by the generator, is the time when generator created most realistic data.\n",
        "\n",
        "\n",
        "\n",
        "### **Relation Between Classification models and GANs**\n",
        "\n",
        "Lets understand the relationship between them with the help of an example.\n",
        "\n",
        "MNIST is a large data base which contains binary images of handwritten digits. \n",
        "\n",
        "![MNIST](https://drive.google.com/uc?id=1Ayjjs9JAx_GVGBKAt7HoItOze57mI731)\n",
        "\n",
        "By simply looking at the database we can simple observe what digits are present in the image. But for machine it is different. The pixel of **digit 2** is different than the digit 2 present in the image.![two](https://drive.google.com/uc?id=1ej27sI5GvOsewGEjBZI2Jzdfs6YgSDHE)\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "As depicted in the left flow chart below, this is the standard setup of a classification model. It will take the hanwritten digit as input which is high dimension object and the ouput is relatively low dimensional object, which is just the identity of the digit itself.\n",
        "\n",
        "![2](https://drive.google.com/uc?id=10NQtHbp_QwSCOFdAPsAzTVV7TzI9jOIb)\n",
        "\n",
        "GANs on the other hand does not fall under this category of Machine learning technique, they are totally different.  \n",
        "This is completely inverse of what we have seen in classification setup. In this idea case, here is no input instead we are asking model to produce plausible handwritten digit and it produces something that could perceptually looks like that it could either be 2, 4,8 or 9.   \n",
        "\n",
        "So, as for inverse you can see that ins and outs of both the models are roughly opposite of each other.\n",
        "\n",
        "Also, in case classification task, not always, but usually it goes from high dimensional object to low dimension object, but in generation case as you can see it is trying to create this high dimensional object.\n",
        "\n",
        " Hence, I hopefully demonstrated you the relationship between both the models.\n",
        "\n",
        "\n",
        "## **Working of GANs**\n",
        "\n",
        "To have a better understanding of working of generators and discriminator. Lets understand this with the example of **Orchestra and its conductor**.  \n",
        "\n",
        "The orchestra trains, practices and tries to create more polished music. The conductor on the other hand is not only thier judge but also their trainer. The conductor observes the quality of the output produced by the orchestra and gives them feedback to acheive a certain style of music. In the same way generator adn discriminator also works together. The more they work together, the better output will be generated.\n",
        "\n",
        "Similarly, a GAN's generator produces new music as the orchestra does. And the discriminator judges whether the music generator creates is realistic and provides feedback on how to make its data more realistic, just as a conductor provides feedback to make an orchestra sound better.\n",
        "\n",
        "\n",
        "### **Training Process**\n",
        "\n",
        "The Generator and the Discriminator are both Neural Networks and they both run in competition with each other in the training phase. The steps are being iterated several times and in this, the Generator and Discriminator gets better and better in their respective task after every iteration.\n",
        "\n",
        "Here are some of the steps taken by GAN during training:\n",
        "\n",
        "* The generator takes in random numbers and returns an image.\n",
        "* This generated image is fed into the discriminator alongside a stream of images taken from the actual, ground-truth dataset.\n",
        "* The discriminator takes in both real and fake images and returns probabilities, a number between 0 and 1, with 1 representing a prediction of authenticity and 0 representing fake.\n",
        "\n",
        "So you have a double feedback loop:\n",
        "\n",
        "* The discriminator is in a feedback loop with the ground truth of the images, which we know.\n",
        "* The generator is in a feedback loop with the discriminator.\n",
        "<br><br>\n",
        "\n",
        "So, basically, GAN is trained in 3 phases in a single round:\n",
        "\n",
        "![Diagram](https://drive.google.com/uc?id=1tIO-9OikiNsD6zVVOX18HM_k3SyKAB3n)\n",
        "\n",
        "Credit: Tenserflow\n",
        "\n",
        "**Latent Random Variable**: Latent random variable, you can think this as a low dimensional space with a very simple distribution like a multivariate Gaussian, that we wil draw samples from and pass to the generator in order for it to produce various kinds of images, not kind of having the same sort of images every time.  \n",
        "\n",
        "* **Part 1**: This is generator training phase. First, we pull from this very simple distribution a latent vector, just think this vector as some kind of small number of dimension. And we use that to feed the generator, which then uses it to produce sample as you can see on the right of the generator. We take that sample and passes through the discriminator, which tries to disctinguish real from fake and since, we are at the beginning the discriminator very easily able to tell that it is fake. And in the very basic case, we kind of use normal two-class classification loss. Since these are all neural networks, we back propagate from the loss, that is, through the output of the discriminator to the generator. Since, we are in the generation training step we hold the weights of the discriminator fixed, that is, we dont make any updates in the dicriminator neural network.  And now we update weights of generator in the direction to better being able to fool the discriminator. With this we are done with the generation step.\n",
        "\n",
        "The next two phases are solely for discriminator.\n",
        "\n",
        "* **Part 2**: Again, we did the same thing and that is to draw some number of noise vectors from the latent space. And we feed them to generator in order to produce some samples, and then we pass them to discriminator, which tries to distinguish real from fake. Here, also we have same sort of classification loss that we have in generation step, but now instead of fooling discriminator, we want the system to say that discriminator is doing poor job if it is unable to distinguish real from fake. And now we perform normal stochastic gradient descent and then we back propagate. Since, we are only focusing on dicriminator in this phase, we back propagate to discriminator from loss. And then we stop here, and we actually updates the weights here in order to become better in distinguishing between real and fake.\n",
        "\n",
        "* **Part 3**: And lastly, we pull some examples from real images and sort of do the same thing that we done in phase 2, so that discriminator is able to tell real images are real, rather than just fake images our fake.\n",
        "\n",
        "With this, we completed our first round. We would this process over and over again, untill the generator would get to a point where the generator starts producing images, that discrimnator really can't tell real from fake. At this point, we stop and our generator is producing high dimensional plausible and realistic looking objects. \n",
        "\n",
        "##### **Types of GANs**\n",
        "\n",
        "Since GANs are one of the recent advancements in artifical intelligence and also a very active topic of research. Therefore, there have been many different types of GAN implementation and some of them have been listed below :\n",
        "\n",
        "1. **SuperResolution GAN (or simply SRGAN)**:  This is one of the techiniques related to what we see in sci-fi movies. Its like where we have an image and after arbritarily zooming of the image, image resolves itself and those details came into light which were not their previously. For example, previously the number plate of a car is not visible, but after zoom in, we got a clear image of the number plate of the car. The goal of SRGAN was to take a low resolution image and create a high-resolution image by inferring or hallucinating the details that were not there previosuly in the original image.\n",
        "\n",
        "  ![2](https://drive.google.com/uc?id=1CM8sBPut39a2CKcFF-QMpzFAC3NpCJVm)\n",
        "\n",
        "  Here, first they had taken the original image and down sample it 4x and then, the down sampled image is being up sampled using ResNet, and then GAN is applied on that ResNet image, which is SRGAN image. As you can observe ofcourse the SRGAN is very close to high resolution original image but it is different from the original image. When you focus on the head neckalce, you can onbserve that details in both SRGAN image and original are quite different. Same you can observe in the necklace worn by the girl.\n",
        "So, SRGAN kind of sharpen the image and makes it high resoltuion but in this process it created something entirely different from the original image. \n",
        "  But I think it is really a cool project, which can sharpen images to such extent. And here is link if you want to read further about the project.  \n",
        "\n",
        "  > **Link** => [SRGAN](https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/image_enhancing.ipynb#scrollTo=ubdupldDypCy)\n",
        "\n",
        "\n",
        "2. **CycleGAN** : CycleGAN; proposed in 2017, is one of the cool techniques which uses GANs, and it is used to solve the problem called as Unpaired Image to Image Translation. As the problem statement itself suggests, it is used to perform the task of image to image translation.\n",
        "\n",
        "  ![2](https://drive.google.com/uc?id=1W_InLfzh_Xa1Tq8ab52J5W_HdzaKY_43)\n",
        "\n",
        "  So, here the task is to map image of Zebras with the image of Horses, where background and everything about the image is exactly the same, but we have just replace image of zebras with the horses in the same manner as you can see in the above image.\n",
        "  \n",
        "  ![2](https://drive.google.com/uc?id=1YB_a9bEVNxIS1wf2YbK5AOGYnW9CMtBv)\n",
        "  \n",
        "  This could also be done other way around.\n",
        "  \n",
        "  > If you wan to further enhace your knowledge about the project I have attached the link of their work below. So, I highly recommend you to visit the link.  \n",
        "  **Link** => [CycleGAN](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/generative/cyclegan.ipynb)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## **Referrences**\n",
        "\n",
        "* https://www.youtube.com/watch?v=qvBhp0e-Kuc\n",
        "* https://www.geeksforgeeks.org/generative-adversarial-network-gan/\n",
        "* https://developers.google.com/machine-learning/gan"
      ]
    }
  ]
}