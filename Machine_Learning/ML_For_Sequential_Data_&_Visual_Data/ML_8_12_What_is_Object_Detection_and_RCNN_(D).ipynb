{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_8_12_What is Object Detection and RCNN_(D).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7beSnN6cvBMY"
      },
      "source": [
        "# **Object Detection and RCNN**\n",
        "<hr>\n",
        "\n",
        ">ðŸ”´ Type of Content : Documentation  \n",
        "ðŸ”´ Domain : Machine Learning  \n",
        "ðŸ”´ Module : Name of the module for every week\n",
        "\n",
        "Object detection is one of the whole lot of computer vision tasks. It is one of the super core task in computer vision and there are lots of applications which use object detection. This is not only used to idetify the multiple objects in an image or in video but also locates these different objects, both of these tasks are done simultaneously. And also while doing identification and localization, object detection can be used to count objects in a scene and determine and track their precise locations, all while accurately labeling them. And due to these tasks, objects detection is the most used computer vision task. As you may already know about its live example that is Tesla cars, these are self-driving cars and use object detection to automate driving.\n",
        "\n",
        "Imagine, for example, the below image that contains one dog, a bicycle and a car. Object detection allows us to classify the types of things found while also locating instances of them within the image.\n",
        "\n",
        "![](https://miro.medium.com/max/739/1*IrptRDRG8IL9o-55BKjbLA.png)\n",
        "> **Credit: Towards Data Science**\n",
        "\n",
        "### **What is Object detection ?**\n",
        "\n",
        "As the name itself suggests, it is used to detect objects either in image or in a video. But what it really does is, it not only idetifies and locates objects, it also tells the precise location of the objects with correct label. In object detection, boxes are also made around different objects in the images with correct labels. \n",
        "\n",
        "In simple words, object detection answers the question : \"what are all the projects present in the image and where are they present in the image?\" This could also be done in case of videos.\n",
        "\n",
        "Object Detection is sometimes confused with Image Recognition/Classification. So, first lets clarify the distinguish between those two.\n",
        "\n",
        "Image classification categories the whole image or it gives only a single label to the whole image. For example, whether the image contains single cat or multiple cats, image recognition would give the image the label of cat in both the cases. Whereas if in same scenario object detection is used, it will only label them as cats in the image itself but would also give the precise location of those cats. So, in case of object detection, model gives multiple labels in a single image and also locates their precise location in the image.  \n",
        "\n",
        "The below image will give you an example how object detection differs from image classification.\n",
        "![](https://i2.wp.com/res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1522766480/1_6j34dAOTijqP6HDFnjxPFA_udggex.png)\n",
        "\n",
        "\n",
        "## **Importance of Object Detection**\n",
        "\n",
        "Object detection is one of the fundamental problems of computer vision. It forms the basis of many other downstream computer vision tasks, for example, instance segmentation, image captioning, object tracking, and more. Specific object detection applications include pedestrian detection, people counting, face detection, text detection, pose detection, or number-plate recognition.\n",
        "\n",
        "\n",
        "\n",
        "The main purpose of object detection is to identify objects or instances, and locate them in images or videos. It uses different techniques from different machine learning algorithms to identify and locate objects. For example, it uses image recognition to identify different objects in the image. And due to these unique ability of object detection it is used in many area such as : \n",
        "\n",
        "* Crowd counting \n",
        "* Self-driving cars\n",
        "* Video surveillance\n",
        "* Face detection\n",
        "\n",
        "## **Challenges with Object Detection**\n",
        "\n",
        "There are certain challenges that the researchers faced while creating model for object detection\n",
        "\n",
        "1. **Variable number of objects**\n",
        "\n",
        "  When training machine learning models, you usually need to represent data into fixed-sized vectors. Since the number of objects in the image is not known beforehand, we would not know the correct number of outputs. Because of this, some post-processing is required, which adds complexity to the model.\n",
        "\n",
        "2. **Sizing**\n",
        "\n",
        "  When doing simple classification, you expect and want to classify objects that cover most of the image. On the other hand, some of the objects you may want to find could be a small as a dozen pixels (or a small percentage of the original image). Traditionally this has been solved with using sliding windows of different sizes, which is simple but very inefficient.\n",
        "\n",
        "3. **Modeling**\n",
        "\n",
        "  A third challenge is solving two problems at the same time. How do we combine the two different types of requirements: location and classification into, ideally, a single model?\n",
        "\n",
        "## **Working of Object Detection**\n",
        "\n",
        "Since, now we know a little bit about object detection and know at which areas it is being used, so lets dive a little deeper and learn how object detection really works.\n",
        "\n",
        "Object detection is a task where we are going to input single RGB image and the output is going to be the set of detected objects. That for each object in the scene we want our model to identify all of the interestin objects in the scene.  \n",
        "So for each of the objects we are going to output several things related to that particular object, one is the category label giving the category to the detected object, other is the bounded box, giving the spatial extent of the objects in the image.  \n",
        "\n",
        "Object Detection can be performed using two approaches :\n",
        "\n",
        "* **Classical Approach**\n",
        "* **Deep Learning Approach**\n",
        "\n",
        "## **1. Classical Approach**\n",
        "\n",
        "There have been many different types of methods throughout the years, we want to focus on the two most popular ones (which are widely used).\n",
        "\n",
        "The first one is the Viola-Jones framework proposed in 2001 by Paul Viola and Michael Jones in the paper Robust Real-time Object Detection. The approach is fast and relatively simple, so much that itâ€™s the algorithm implemented in point-and-shoot cameras which allows real-time face detection with little processing power.\n",
        "\n",
        "At the high level, it works by generating different (possibly thousands) simple binary classifiers using Haar features. These classifiers are assessed with a multi-scale sliding window in cascade and dropped early in case of a negative classification.\n",
        "\n",
        "Another traditional and similar method is using Histogram of Oriented Gradients (HOG) features and Support Vector Machine (SVM) for classification. It still requires a multi-scale sliding window, and even though itâ€™s superior to Viola-Jones, itâ€™s much slower.\n",
        "\n",
        "\n",
        "## **2. Deep Learning Approach**\n",
        "\n",
        "With the entry of Deep Learning in AI domain, most of the tasks that uses lots of ample amount of time to get solved, now they just got simplified. Deep learning is the real game changer in Aritfical Intellignece and Machine Learning and especially in the case of computer vision. For example, in case of image recognition, if we want to detect image of polar bear, developers have to themselves mention all the details like position of eyes, face mouth, strength of light focusing on the bear. And if by any chance polar bear has its eyes closed, then they have to take of those case manually, so even though they know all the logic but most of thier time got spended in writing these many edge case, so with the introduction og neural networks, their workload have decreased 10x folds. And deep learning has been used extensively since it outperforms classical approaches. \n",
        "And object detection is no exception, with the intro of deep learning, our models could perform more accurately and in less time. In deeplearning there are two types of object detection network that could be used.\n",
        "\n",
        "1. **One Stage Network** : In single-stage networks, such as YOLO v2, the CNN produces network predictions for regions across the entire image using anchor boxes, and the predictions are decoded to generate the final bounding boxes for the objects. Single-stage networks can be much faster than two-stage networks, but they may not reach the same level of accuracy, especially for scenes containing small objects.\n",
        "\n",
        "  ![](https://www.mathworks.com/discovery/object-detection/_jcr_content/mainParsys3/discoverysubsection_/mainParsys3/image_copy_1370671982.adapt.1200.medium.jpg/1630396980328.jpg)\n",
        "  > **Credit : mathworks**\n",
        "\n",
        "\n",
        "2. **Two Stage Networks** : The initial stage of two-stage networks, such as R-CNN and its variants, identifies region proposals, or subsets of the image that might contain an object. The second stage classifies the objects within the region proposals. Two-stage networks can achieve very accurate object detection results; however, they are typically slower than single-stage networks.\n",
        "\n",
        "  ![](https://www.mathworks.com/discovery/object-detection/_jcr_content/mainParsys3/discoverysubsection_/mainParsys3/image_copy_1403980522.adapt.1200.medium.jpg/1630396980289.jpg)\n",
        "  > High-level architecture of R-CNN (top) and Fast R-CNN (bottom) object detection.\n",
        "\n",
        "  **Credit : mathworks**  \n",
        "  \n",
        "  \n",
        "  There are many deep learning approaches through which we could perform object detection. Out of which we will some of them below:  \n",
        "<br>\n",
        "\n",
        "* **OverFeat** \n",
        "\n",
        "  One of the first advances in using deep learning for object detection was OverFeat from NYU published in 2013. They proposed a multi-scale sliding window algorithm using Convolutional Neural Networks (CNNs).\n",
        "\n",
        "  ![](https://vitalab.github.io/article/images/overfeat/sc2.png)\n",
        "  > **Credit: vitalab**\n",
        "\n",
        "\n",
        "* **YOLO**\n",
        "\n",
        "  YOLO stands for You Only Look Once. YOLO family of models are a series of end-to-end deep learning models designed for fast object detection, developed by Joseph Redmon.\n",
        "  In simple words, YOLO is an algorithm that uses neural networks to provide real-time object detection. This algorithm is popular because of its speed and accuracy. It has been used in various applications to detect traffic signals, people, parking meters, and animals.\n",
        "\n",
        "  ![](https://pyimagesearch.com/wp-content/uploads/2018/11/yolo_design.jpg)\n",
        "  > **Credit: pyimagesearch**\n",
        "\n",
        "\n",
        "* **RCNN**\n",
        "\n",
        "  It is also one of the deep learning techniques used in object detection. RCNN stands for **Region-based Convolutional Neural Network**. The key concept behind the R-CNN series is region proposals. So lets understand about region porposals.\n",
        "<br>\n",
        "\n",
        "  **Region Proposals**\n",
        "\n",
        "    This neural network which kind of provides small boxes in the image, and there is high probability that this neural network covers every object inside the image. And they are called region because the task of this neural network is to cover every regions inside the image.  \n",
        "    \n",
        "    ![Image](https://drive.google.com/uc?id=1sqZK1HqfZvSy2Wjks_AMtLzd96VYBaoz)\n",
        "\n",
        "    This neural network looks for blob type region or edges in the input images and draw squares around those regions. These sometimes also use other kinds of low level image processing cues to look for image regions that have high probability of containing objects\n",
        "    <br>\n",
        "\n",
        "\n",
        "  #### **Types of RCNN**\n",
        "\n",
        "* **Fast RCNN**\n",
        "\n",
        "  Similar to R-CNN, it used Selective Search to generate object proposals, but instead of extracting all of them independently and using SVM classifiers, it applied the CNN on the complete image and then used both Region of Interest (RoI) Pooling on the feature map with a final feed forward network for classification and regression.\n",
        "\n",
        "  ![](https://i.ytimg.com/vi/xzw3lcdllOU/maxresdefault.jpg)\n",
        "\n",
        "\n",
        "* **Faster RCNN**\n",
        "\n",
        "  Faster R-CNN added what they called a Region Proposal Network (RPN), in an attempt to get rid of the Selective Search algorithm and make the model completely trainable end-to-end. We wonâ€™t go into details on what the RPNs does, but in abstract it has the task to output objects based on an \"objectness\" score. These objects are used by the RoI Pooling and fully connected layers for classification.\n",
        "\n",
        "  ![](https://miro.medium.com/max/1400/1*S_-8lv4zP3W8IVfGP6_MHw.jpeg)\n",
        "\n",
        "\n",
        "* **Mask RCNN**\n",
        "\n",
        "  Mask RCNN is a deep neural network aimed to solve instance segmentation problem in machine learning or computer vision. In other words, it can separate different objects in a image or a video. You give it a image, it gives you the object bounding boxes, classes and masks.\n",
        "\n",
        "  ![](https://miro.medium.com/max/1400/1*ui1roGvi_F77TY07PdaI8w.png)\n",
        "\n",
        "  \n",
        "\n",
        "  #### **Working of R-CNN**\n",
        "\n",
        "  Below Image contains the working details of R-CNN for object detection.\n",
        "    ![](https://miro.medium.com/max/1050/0*Esmqth8McxPM2YtB.png)\n",
        "\n",
        "  As can be seen in the image above first, we need to extract region proposals. Then, we need to resize (wrap) all the extracted crops and then pass them through a network.  \n",
        "\n",
        "  Finally, a network assigns a category from C + 1, including the â€˜backgroundâ€™ label, categories for a given crop. Additionally, it predicts delta Xs and Ys to shape a given crop.\n",
        "\n",
        "  #### **Extracting Region**\n",
        "\n",
        "  Selective search is one of the most famous methods for region proposals. It is some kind of algorithm that we could run on CPU and it gave about 2000 region propsals per image in it's original paper in a couple of seconds. And these 2000 region proposals have the high probability of covering all of the interesting objects in an image. Therefore,  it is used for most of these object detection tasks.\n",
        "\n",
        "  #### **Labelling Proposals**\n",
        "\n",
        "  Now comes the important step of labelling those proposals that we extracted in previous step. These are need to be labelled so that we can send them for training. Therefore, the authors label all the proposals having IOU of at least 0.5 with any of the ground-truth bounding boxes with their corresponding classes. However, all other region proposals that have an IOU of less than 0.3 are labelled as background. Thus, the rest of them are simply ignored.\n",
        "    \n",
        "  \n",
        "  #### **Bounding Box Regression**\n",
        "\n",
        "  ![](https://miro.medium.com/max/491/1*3XFQzZaMiirq5990312vYQ.png)\n",
        "\n",
        "  The image above shows deltas that are to be predicted by CNN. So, x, y are centre coordinates. whereas w, h are width and height respectively. Finally, G and P stand for ground-truth bounding box and region proposal respectively. It is important to note that the bounding box loss is only calculated for positive samples.\n",
        "\n",
        "  #### **Loss**\n",
        "\n",
        "  The total loss is calculated as the sum of classification and regression losses. However, there is a coefficient lambda for the latter one, which is 1,000 in the original paper. Note that the regression loss is ignored for negative examples.\n",
        "\n",
        "  #### **Architecture**\n",
        "\n",
        "  Typically, we pass the resized crops through VGG 16 or ResNet 50 in order to get features. They are subsequently passed through fully connected layers that output predictions.  \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sN2eP8byoCl7"
      },
      "source": [
        "## **Applications of Object detection**\n",
        "\n",
        "Object Detection is one of the most used techniques in most of the applications in today's modern world. Object detection and\n",
        "recognition is applied in many areas of computer vision,\n",
        "including image retrieval, security, surveillance, automated\n",
        "vehicle systems and machine inspection. Below are some of its important application.\n",
        "<br><Br>\n",
        "\n",
        "* **OPTICAL CHARACTER RECOGNITION** \n",
        "  \n",
        "  Optical character recognition or optical character reader, often abbreviated as OCR, is the mechanical or electronic conversion of images of typed, handwritten or printed text into machine-encoded text, whether from a scanned document, a photo of a document, a scene-photo (for example the text on signs and billboards in a landscape photo) or from subtitle text superimposed on an image, we are extracting characters from the image or video. As you can see in the below image we are extracting the characters from car's number plate.\n",
        "\n",
        "  ![](https://drive.google.com/uc?id=1KahZPJoVg-D_XMevZFT6zDome_B6V028)\n",
        "  > **Credit: IRJET**\n",
        "\n",
        "* **SELF DRIVING CARS**\n",
        "\n",
        "  One of the most used application of object detection is autonomous driving. In order for a car to decide what\n",
        "to do in next step whether accelerate, apply brakes or turn, it\n",
        "needs to know where and what all the objects are around the car. 'Where' is required to know the location of those objects and what is required to know their size. So for this kind of work object detection is essential to train the car, to detect known set of objects such as cars, pedestrians, traffic lights, road signs, bicycles, motorcycles, etc.  \n",
        "<br>\n",
        "One of the popular example of self driing cars is the Tesla self driving cars. And these cars are on a hype in the market right now.\n",
        "\n",
        "  ![](https://www.gigabyte.com/FileUpload/Global/Insight/Article/154/o202009241819172567.jpg)\n",
        "\n",
        "* **TRACKING OBJECTS**\n",
        "\n",
        "  Object detection system is also used in tracking the\n",
        "objects, for example tracking a ball during a football match,\n",
        "tracking movement of a cricket bat, tracking a person in a\n",
        "video. Object tracking has a variety of uses, some of which are\n",
        "surveillance and security, traffic monitoring, video\n",
        "communication, robot vision and animation. \n",
        "\n",
        "  ![](https://venturebeat.com/wp-content/uploads/2020/04/b9355a07-e2bb-4f05-9662-bdce9c625cb4-e1586377374664.png?w=1200&strip=all)\n",
        "\n",
        "\n",
        "* **FACE DETECTION AND RECOGNITION**\n",
        "\n",
        "  It is one of the most widely used application of Object Detection. From security to Instagram filters, in both of them facial recognition and detection is widely used. We must have heard of face lock in our android, that uses face recognition to recognise the face of the user and then unlocks the phone. Similarly, in case of instagram or facebook filters, face detection is used to apply different filters.\n",
        "\n",
        "  ![](https://i.pinimg.com/originals/a2/84/69/a28469f8885b11fdf38fdfd7b32f168e.png)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## **Referrences**\n",
        "\n",
        "* https://tryolabs.com/blog/2017/08/30/object-detection-an-overview-in-the-age-of-deep-learning\n",
        "\n",
        "* https://viso.ai/deep-learning/object-detection/\n",
        "\n",
        "* https://www.mathworks.com/discovery/object-detection.html\n",
        "\n",
        "* https://www.irjet.net/archives/V6/i4/IRJET-V6I4920.pdf"
      ]
    }
  ]
}
