{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_8.18_Image_Denoising_#7511.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WA7PIUwgiTeg"
      },
      "source": [
        "# **Image Denoising**\n",
        "\n",
        "<br>\n",
        "\n",
        "* Image Denoising is the process of removing noise from the Images\n",
        "\n",
        "* The noise present in the images may be caused by various intrinsic or extrinsic conditions which are practically hard to deal with. \n",
        "* The problem of Image Denoising is a very fundamental challenge in the domain of Image processing and Computer vision. \n",
        "* Therefore, it plays an important role in a wide variety of domains where getting the original image is really important for robust performance.\n",
        "<br>\n",
        "\n",
        "<img src=\"https://dmitryulyanov.github.io/assets/deep-image-prior/teaser/cropped_02.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USDLCYUQlg0i"
      },
      "source": [
        "* Traditional image denoising algorithms always assume the noise to be homogeneous Gaussian distributed. However, in practice, the noise on real images can be much more complex. Such noise on real images is called Real-noise or Blind-noise. Traditional filters fail to perform well on images with such noise.\n",
        "\n",
        "* We can remove the noise from the noisy images using **autoencoders** or **encoder-decoder networks**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pzJuAUmrSMr"
      },
      "source": [
        "##**Autoencoders**\n",
        "\n",
        "* Autoencoder is an unsupervised artificial neural network that is trained to copy its input to output. \n",
        "* In the case of image data, the autoencoder will first encode the image into a lower-dimensional representation, then decodes that representation back to the image. \n",
        "* Encoder-Decoder automatically consists of the following two structures:\n",
        "\n",
        "  1. The encoder- This network downsamples the data into lower dimensions.\n",
        "  2. The decoder- This network reconstructs the original data from the lower dimension representation.\n",
        "* The lower dimension (i.e, output of encoder network) representation is usually known as latent space representation.\n",
        "<br>\n",
        "<img src=\"https://miro.medium.com/max/750/1*sahNK4wy4teFA0r6tJJwKQ.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aV8o2Djtp2d8"
      },
      "source": [
        "##**How Autoencoders Work ?**\n",
        "\n",
        "* The network is provided with original images x, as well as their noisy version x~. The network tries to reconstruct its output x’ to be as close as possible to the original image x. By doing so, it learns how to denoise images.\n",
        "\n",
        "* the encoder model turns the input into a small dense representation. The decoder model can be seen as a generative model which is able to generate specific features.\n",
        "\n",
        "* Both encoder and decoder networks are usually trained as a whole. The loss function penalizes the network for creating output x’ that differs from the original input x.\n",
        "* By doing so the encoder learns to preserve as much of the relevant information needed in the limitation of the latent space, and cleverly discard irrelevant parts, e.g. noise. The decoder learns to take the compressed latent information and reconstruct it into a full error-free input.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZR3pki_a4U1G"
      },
      "source": [
        "##**Hyperparameters Of Autoencoders**\n",
        "\n",
        "* There are mainly 4 parameters that we need to set before training the autoencoder\n",
        "* **Code size**: This represents the number of nodes in the middle layer. The smaller the code size more the compression is and if you want less compression then increase the code size.\n",
        "* **Number of Layers**: In the above architecture image there are only 2 layers in encoder and decoder but we can make it as deep we want it to be.\n",
        "* **The number of nodes per layer**: Usually what happens is the number of nodes per layer decreases with each subsequent layer of an encoder and then starts increasing again with each subsequent layer of the decoder. The decoder is symmetric to the structure of the encoder but that’s not a requirement.\n",
        "* **Loss function**: The popular choices here are mean squared error(MSE) or binary cross-entropy. If the input values are in the range [0,1] then binary cross-entropy is favored as compared to MSE. Otherwise, we just use MSE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tN0GL1XR5Twg"
      },
      "source": [
        "##**Implementaion**\n",
        "\n",
        "* Let's implement an autoencoder to denoise hand-written digits. The input is a 28x28 grey scaled image, building a 784-elements vector.\n",
        "* The encoder network is a single dense layer with 64 neurons. Therefore the latent space will have dimension 64. A rectified units (ReLu) activation function is attached to each neuron in the layer, and determines whether it should be activated (“fired”) or not, based on whether each neuron’s input is relevant for the autoencoder’s prediction. * The activation function also helps normalize the output of each neuron to a range between 1 and 0.\n",
        "* The decoder network is a single dense layer with 784 neurons, corresponding to a 28x28 greyscaled output image. A sigmoid activation function is used to compare the encoder input versus the decoder output.\n",
        "* Binary cross-entropy is used as a loss function and Adadelta as an optimizer for minimizing the loss function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8tSEm0u51cO"
      },
      "source": [
        "import keras\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "# input layer\n",
        "input_img = Input(shape=(784,))\n",
        "\n",
        "# autoencoder\n",
        "encoding_dim = 32  \n",
        "encoded = Dense(encoding_dim, activation='relu')(input_img)\n",
        "encoded_input = Input(shape=(encoding_dim,))\n",
        "decoded = Dense(784, activation='sigmoid')(encoded)\n",
        "autoencoder = Model(input_img, decoded)\n",
        "decoder_layer = autoencoder.layers[-1]\n",
        "decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
        "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bi3-nYwF6Pag"
      },
      "source": [
        "The [MNIST](http://yann.lecun.com/exdb/mnist/) dataset is a well-known database of handwritten digits that is widely used for training and testing in the field of machine learning. We use it here to generate synthetic noisy digits by applying a Gaussian noise matrix and clipping the images between 0 and 1.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2Bpi5he6h9B"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "%matplotlib inline\n",
        "\n",
        "# get MNIST images, clean and with noise\n",
        "def get_mnist(noise_factor=0.5):\n",
        "  (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "  x_train = x_train.astype('float32') / 255.\n",
        "  x_test = x_test.astype('float32') / 255.\n",
        "  x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))\n",
        "  x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))\n",
        "\n",
        "  x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) \n",
        "  x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) \n",
        "\n",
        "  x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
        "  x_test_noisy = np.clip(x_test_noisy, 0., 1.)\n",
        "  \n",
        "  return x_train, x_test, x_train_noisy, x_test_noisy, y_train, y_test\n",
        "\n",
        "x_train, x_test, x_train_noisy, x_test_noisy, y_train, y_test = get_mnist()\n",
        "\n",
        "# plot n random digits\n",
        "# use labels to specify which digits to plot\n",
        "def plot_mnist(x, y, n=10, randomly=False, labels=[]):\n",
        "  plt.figure(figsize=(20, 2))\n",
        "  if len(labels)>0:\n",
        "    x = x[np.isin(y, labels)]\n",
        "  for i in range(1,n,1):\n",
        "      ax = plt.subplot(1, n, i)\n",
        "      if randomly:\n",
        "        j = random.randint(0,x.shape[0])\n",
        "      else:\n",
        "        j = i\n",
        "      plt.imshow(x[j].reshape(28, 28))\n",
        "      plt.gray()\n",
        "      ax.get_xaxis().set_visible(False)\n",
        "      ax.get_yaxis().set_visible(False)\n",
        "  plt.show()\n",
        "  \n",
        "plot_mnist(x_test_noisy, y_test, randomly=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEqsVOM36mjn"
      },
      "source": [
        "The autoencoder will minimize the difference between noisy and clean images. By doing this it will learn how to remove noise from any unseen hand-written digit, that was produced with similar noise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-i6F9Kv6wvW"
      },
      "source": [
        "# flatten the 28x28 images into vectors of size 784.\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "x_train_noisy = x_train_noisy.reshape((len(x_train_noisy), np.prod(x_train_noisy.shape[1:])))\n",
        "x_test_noisy = x_test_noisy.reshape((len(x_test_noisy), np.prod(x_test_noisy.shape[1:])))\n",
        "\n",
        "#training\n",
        "history = autoencoder.fit(x_train_noisy, x_train,\n",
        "                          epochs=100,\n",
        "                          batch_size=128,\n",
        "                          shuffle=True,\n",
        "                          validation_data=(x_test_noisy, x_test))\n",
        "                          \n",
        "# plot training performance\n",
        "def plot_training_loss(history):\n",
        "\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  epochs = range(1, len(loss) + 1)\n",
        "\n",
        "  plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "  plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "  plt.title('Training and validation loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "plot_training_loss(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2sc8_fd70VB"
      },
      "source": [
        "<img src=\"https://miro.medium.com/max/602/1*PLBqcw1kPpsjMcij3VO6pA.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReiiICHC608Y"
      },
      "source": [
        "Now we can use the trained autoencoder to clean unseen noisy input images and plot them against their cleaned version."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWSTRoU57cXb"
      },
      "source": [
        "# plot de-noised images\n",
        "def plot_mnist_predict(x_test, x_test_noisy, autoencoder, y_test, labels=[]):\n",
        "  \n",
        "  if len(labels)>0:\n",
        "    x_test = x_test[np.isin(y_test, labels)]\n",
        "    x_test_noisy = x_test_noisy[np.isin(y_test, labels)]\n",
        "\n",
        "  decoded_imgs = autoencoder.predict(x_test)\n",
        "  n = 10  \n",
        "  plt.figure(figsize=(20, 4))\n",
        "  for i in range(n):\n",
        "      ax = plt.subplot(2, n, i + 1)\n",
        "      plt.imshow(x_test_noisy[i].reshape(28, 28))\n",
        "      plt.gray()\n",
        "      ax.get_xaxis().set_visible(False)\n",
        "      ax.get_yaxis().set_visible(False)\n",
        "\n",
        "      ax = plt.subplot(2, n, i + 1 + n)\n",
        "      plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "      plt.gray()\n",
        "      ax.get_xaxis().set_visible(False)\n",
        "      ax.get_yaxis().set_visible(False)\n",
        "  plt.show()\n",
        "  return decoded_imgs, x_test\n",
        " \n",
        "decoded_imgs_test, x_test_new = plot_mnist_predict(x_test, x_test_noisy, autoencoder, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HL-zlwKz74vy"
      },
      "source": [
        "<img src=\"https://miro.medium.com/max/1050/1*pzPbp765q8NlgJWg2PXXRQ.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WG5XDVbh8pSm"
      },
      "source": [
        "Overall, the noise is removed very well. The white dots which were introduced artificially on the input images have disappeared from the cleaned images. The digits can be recognized visually."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErrUwWzB8t55"
      },
      "source": [
        "In this article, I described an image denoising technique with a practical guide on how to build autoencoders with Python.I hope you got Basic Understanding about denoising the images.\n",
        "\n",
        "Thanks for reading !"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcEBpMk48NP6"
      },
      "source": [
        "##**References**\n",
        "\n",
        "https://www.jeremyjordan.me/autoencoders/\n",
        "\n",
        "https://www.tensorflow.org/tutorials/generative/autoencoder"
      ]
    }
  ]
}