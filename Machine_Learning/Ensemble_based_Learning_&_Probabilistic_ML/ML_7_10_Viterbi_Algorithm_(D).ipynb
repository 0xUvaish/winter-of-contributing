{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **<ins>Viterbi Algorithm</ins>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Viterbi algorithm is a <b>dynamic programming algorithm</b> used for obtaining the maximum a posteriori probability estimate of the most likely sequence of hidden states (the Viterbi path) that results in a sequence of observed events, especially in the context of Markov information sources and hidden Markov models (HMM).\n",
    "<br>\n",
    "The purpose of the Viterbi algorithm is to make an inference based on a trained model and some observed data. In decoding problem we need to find the <b>most probable</b> hidden state in every iteration of t."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "Here, the example has two states and three possible observations(emissions). There are five elements of HMM which needs to be adjusted:\n",
    "- states: these are the hidden states which are not directly observed, their presence is observed by observation symbols that hidden states emits.\n",
    "- observations: it refers to the data we know and can observe.\n",
    "- start probability: It is a matrix of the initial probability of the state at time t=0. In this case the probability that a person is healthy on the first day is 0.6, while the probability of having fever is 0.4. When the observation sequence starts, initial hidden state which emits symbol(observation) is decided from initial transition pobability.\n",
    "- transition: transition probability is the probability of moving from one state of a system into another state.\n",
    "- emission: emission probability refers to the relationship between the hidden state in the model and the observations as provided by the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00588: ['Healthy', 'Healthy', 'Healthy']\n",
      "0.01512: ['Healthy', 'Healthy', 'Fever']\n",
      "['Healthy', 'Healthy', 'Fever']\n"
     ]
    }
   ],
   "source": [
    "# five elements for HMM\n",
    "states = ('Healthy', 'Fever')\n",
    "observations = ('normal', 'cold', 'dizzy') \n",
    "start_probability = {'Healthy': 0.6, 'Fever': 0.4}\n",
    "\n",
    "transition_probability = {\n",
    "   'Healthy' : {'Healthy': 0.7, 'Fever': 0.3},\n",
    "   'Fever' :   {'Healthy': 0.4, 'Fever': 0.6},\n",
    "   }\n",
    " \n",
    "emission_probability = {\n",
    "   'Healthy' : {'normal': 0.5, 'cold': 0.4, 'dizzy': 0.1},\n",
    "   'Fever'   : {'normal': 0.1, 'cold': 0.3, 'dizzy': 0.6},\n",
    "   }\n",
    "    \n",
    "    \n",
    "def Viterbi_algo(obs, states, s_pro, t_pro, e_pro):\n",
    "    path = { s:[] for s in states} # init path: path[s] represents the path ends with s\n",
    "    curr_prob = {}\n",
    "    for s in states:\n",
    "        curr_prob[s] = s_pro[s]*e_pro[s][obs[0]]\n",
    "    for i in range(1, len(obs)):\n",
    "        last_pro = curr_prob\n",
    "        curr_prob = {}\n",
    "        for curr_state in states:\n",
    "            max_pro, last_sta = max(((last_pro[last_state]*t_pro[last_state][curr_state]*e_pro[curr_state][obs[i]], last_state) \n",
    "                       for last_state in states))\n",
    "            curr_prob[curr_state] = max_pro\n",
    "            path[curr_state].append(last_sta)\n",
    "\n",
    "    # find the final largest probability\n",
    "    max_pro = -1\n",
    "    max_path = None\n",
    "    for s in states:\n",
    "        path[s].append(s)\n",
    "        if curr_prob[s] > max_pro:\n",
    "            max_path = path[s]\n",
    "            max_pro = curr_prob[s]\n",
    "        print ('%s: %s'%(curr_prob[s], path[s])) # different path and their probability\n",
    "    return max_path\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    obs = ['normal', 'cold', 'dizzy']\n",
    "    print (Viterbi_algo(obs, states, start_probability, transition_probability, emission_probability))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the steps of the states are 'Healthy Healthy Fever' with largest probability of 0.01512. This reveals that the observations ['normal', 'cold', 'dizzy'] were most likely generated by states ['Healthy', 'Healthy', 'Fever']. \n",
    "<br> \n",
    "Here is the graphical representation of given example of HMM:\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/0/0c/An_example_of_HMM.png/450px-An_example_of_HMM.png\" style=\"width:40%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "- https://en.wikipedia.org/wiki/Viterbi_algorithm\n",
    "- https://towardsdatascience.com/hidden-markov-model-hmm-simple-explanation-in-high-level-b8722fa1a0d5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
