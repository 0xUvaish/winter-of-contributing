{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **<ins>Bootstrap Aggregation</ins>**\n",
    "**Type of Content** : Documentation\n",
    "\n",
    "**Domain** : Machine Learning\n",
    "\n",
    "**Module** : Ensemble based Learning & Probabilistic ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bootstrap aggregation, or bagging, is a popular ensemble method that fits a decision tree on different bootstrap samples of the training dataset. This technique reduces overfitting of the model and handles missing values effectively.\n",
    "<br>Let's understand how bagging works with following diagram:\n",
    "<img src=\"https://cdn.inblog.in/user/uploads/b8d6e32cb5c1dbdb648eae77b109cdf1.jpg\" style=\"width:70%\">\n",
    "\n",
    "Consider a dataset with N observations and M features. Now sample from data is drawn with replacement which contains both observations and features. Similarly, certain number of subsets of data are collected with replacement known as Bootstrap samples. <br>\n",
    "These bootstrap samples are now used for training the model parallely. The prediction obtained from all these models are aggregated in order to get the final outcome known as aggregation. Incase of classification, Voting is used. \n",
    "\n",
    "The structure of the bagging procedure can be divided into three essential elements:\n",
    "\n",
    "- Different Training Datasets: Create a different sample of the training dataset for each ensemble model.\n",
    "- High-Variance Model: Train the same high-variance model on each sample of the training dataset.\n",
    "- Average Predictions: Use statistics to combine predictions.\n",
    "\n",
    "Here we will implement <b>Bagging for Classification</b>:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset\n",
    "First we will create a synthetic binary classification problem with 1,000 examples and 20 input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 20) (1000,)\n"
     ]
    }
   ],
   "source": [
    "# test classification dataset\n",
    "from sklearn.datasets import make_classification\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=5)\n",
    "# summarize the dataset\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate a Bagging algorithm on the dataset\n",
    "\n",
    "We will evaluate the model using repeated stratified k-fold cross-validation, with three repeats and 10 folds. We will report the mean and standard deviation of the accuracy of the model across all repeats and folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.858 (0.041)\n"
     ]
    }
   ],
   "source": [
    "# evaluate bagging algorithm for classification\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=5)\n",
    "# define the model\n",
    "model = BaggingClassifier()\n",
    "# evaluate the model\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make predictions for classification\n",
    "\n",
    "The bagging ensemble is fit on all available data, then the predict() function can be called to make predictions on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: 1\n"
     ]
    }
   ],
   "source": [
    "# make predictions using bagging for classification\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "# dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=5)\n",
    "model = BaggingClassifier()\n",
    "# fit the model on the whole dataset\n",
    "model.fit(X, y)\n",
    "# make a single prediction\n",
    "row = [[-4.7705504,-1.88685058,-0.96057964,2.53850317,-6.5843005,3.45711663,-7.46225013,2.01338213,-0.45086384,-1.89314931,-2.90675203,-0.21214568,-0.9623956,3.93862591,0.06276375,0.33964269,4.0835676,1.31423977,-2.17983117,3.1047287]]\n",
    "yhat = model.predict(row)\n",
    "print('Predicted Class: %d' % yhat[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging Hyperparameters\n",
    "There are various parameters which can be considered tuning for the Bagging ensemble and their effect on model performance. We will explore the number of decision trees used in the ensemble.\n",
    "\n",
    "Generally, the number of trees is increased until the model performance stabilizes. Intuition might suggest that more trees will lead to overfitting, although this is not the case. Bagging and related ensemble of decision trees algorithms (like random forest) appear to be somewhat immune to overfitting the training dataset given the stochastic nature of the learning algorithm.\n",
    "\n",
    "Here we are exploring the effect of the number of trees with values between 10 to 1000. A box and whisker plot is created for the distribution of accuracy scores for each configured number of trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0.863 (0.037)\n",
      "50 0.874 (0.036)\n",
      "100 0.884 (0.038)\n",
      "500 0.883 (0.041)\n",
      "1000 0.886 (0.037)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# explore bagging ensemble number of trees effect on performance\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# get the dataset\n",
    "def get_dataset():\n",
    "    X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=5)\n",
    "    return X, y\n",
    "\n",
    "# list of models to evaluate\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    # number of trees to consider\n",
    "    n_trees = [10, 50, 100, 500, 500, 1000]\n",
    "    for n in n_trees:\n",
    "        models[str(n)] = BaggingClassifier(n_estimators=n)\n",
    "    return models\n",
    "\n",
    "# evaluate model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "    # define the evaluation procedure\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    # evaluate the model and collect the results\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    return scores\n",
    "\n",
    "X, y = get_dataset()\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    # evaluate the model\n",
    "    scores = evaluate_model(model, X, y)\n",
    "    # store the results\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    # display the performance parallely\n",
    "    print('%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "- https://machinelearningmastery.com/essence-of-bootstrap-aggregation-ensembles/\n",
    "- https://corporatefinanceinstitute.com/resources/knowledge/other/bagging-bootstrap-aggregation/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
